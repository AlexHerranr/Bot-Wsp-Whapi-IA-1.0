# üìã Funcionalidades Media para Bot WhatsApp

## üéØ Etapa 1: Detecci√≥n de Respuestas Citadas ‚úÖ

### Descripci√≥n
Esta funcionalidad detecta cuando un usuario responde a un mensaje espec√≠fico (quoted/reply) y enriquece el contexto agregando informaci√≥n del mensaje citado.

### Implementaci√≥n Completada

#### 1. Cambios en el C√≥digo

**Archivo: `src/utils/userStateManager.ts`**
- Agregados campos `lastInputVoice` y `quotedMessagesCount` a la interface `UserState`

**Archivo: `src/app-unified.ts`**
- Importado tipo `UserState` desde `userStateManager.js`
- Creado Map global `globalUserStates` para mantener estados de usuario
- Agregada funci√≥n helper `getTimestamp()`
- Implementada l√≥gica de detecci√≥n en el webhook handler

#### 2. Variables de Entorno Agregadas

En `.env` y `.env.example`:
```env
# === NUEVAS FUNCIONALIDADES MEDIA ===
ENABLE_REPLY_DETECTION=false
ENABLE_IMAGE_PROCESSING=false
ENABLE_VOICE_TRANSCRIPTION=false
ENABLE_VOICE_RESPONSES=false

# Configuraci√≥n adicional...
```

#### 3. C√≥mo Funciona

Cuando un usuario responde a un mensaje:
1. El webhook detecta el campo `context.quoted_content`
2. Extrae el texto del mensaje citado
3. Enriquece el mensaje actual con el contexto
4. Formato: `[Usuario responde a: "texto citado..."] mensaje actual`
5. El mensaje enriquecido se env√≠a a OpenAI con contexto completo

### Activaci√≥n

1. En tu archivo `.env`, cambia:
   ```env
   ENABLE_REPLY_DETECTION=true
   ```

2. Reinicia el bot:
   ```bash
   npm run dev
   ```

### Pruebas

#### Prueba Manual
1. En WhatsApp, env√≠a un mensaje al bot
2. Responde a ese mensaje usando la funci√≥n de responder/citar
3. Verifica en los logs que aparezca: `üì± Respuesta detectada a:`

#### Script de Prueba
```bash
node scripts/test-reply-detection.js
```

### Logs y Monitoreo

Los siguientes logs se generan:
- `QUOTED_MESSAGE_DETECTED` - Cuando se detecta una respuesta citada
- Console log con emoji üì± para identificaci√≥n visual r√°pida

### M√©tricas

El sistema rastrea:
- `quotedMessagesCount` - N√∫mero de respuestas citadas por usuario
- `lastMessageTime` - √öltima actividad del usuario

### Pr√≥ximas Etapas

- [ ] Etapa 2: Procesamiento de Im√°genes
- [ ] Etapa 3: Transcripci√≥n de Voz
- [ ] Etapa 4: Respuestas de Voz

### Troubleshooting

**Problema**: No se detectan las respuestas citadas
- Verifica que `ENABLE_REPLY_DETECTION=true` en `.env`
- Confirma que el webhook est√° recibiendo el campo `context`
- Revisa los logs para mensajes de error

**Problema**: El contexto no se agrega correctamente
- Verifica la estructura del mensaje en los logs
- Aseg√∫rate de que el mensaje citado tenga contenido de texto

---

## üéØ Etapa 3: Transcripci√≥n de Voz ‚úÖ

### Descripci√≥n
Esta funcionalidad transcribe autom√°ticamente las notas de voz enviadas por los usuarios usando OpenAI Whisper API, convirtiendo el audio en texto para que el bot pueda procesarlo y responder adecuadamente.

### Implementaci√≥n Completada

#### 1. Cambios en el C√≥digo

**Archivo: `src/app-unified.ts`**
- Agregada funci√≥n `transcribeAudio()` para procesar audio con Whisper API
- Implementado manejo de mensajes tipo 'voice', 'audio' y 'ptt' (Push to Talk)
- Transcripci√≥n as√≠ncrona con fallbacks para errores
- Marcado de estado `lastInputVoice` para respuestas contextuales

#### 2. C√≥mo Funciona

Cuando un usuario env√≠a una nota de voz:
1. El webhook detecta mensaje tipo 'voice', 'audio' o 'ptt'
2. Extrae la URL del audio
3. Descarga el audio y valida el tama√±o (m√°x. 25MB)
4. Env√≠a a OpenAI Whisper API (modelo whisper-1)
5. Recibe transcripci√≥n en espa√±ol
6. Agrega al buffer: `üé§ [transcripci√≥n del audio]`
7. Marca `lastInputVoice = true` para posibles respuestas de voz

### Configuraci√≥n

Variables de entorno relevantes:
```env
ENABLE_VOICE_TRANSCRIPTION=false    # Toggle principal
WHISPER_LANGUAGE=es                 # Idioma de transcripci√≥n
MAX_AUDIO_SIZE=26214400            # 25MB m√°ximo
MAX_AUDIO_DURATION=300             # 5 minutos m√°ximo
```

### Activaci√≥n

1. En tu archivo `.env`, cambia:
   ```env
   ENABLE_VOICE_TRANSCRIPTION=true
   ```

2. Reinicia el bot

### Pruebas

#### Prueba Manual
1. Env√≠a una nota de voz desde WhatsApp
2. Verifica en los logs: `üé§ Procesando nota de voz...`
3. Confirma que aparezca: `üé§ Transcripci√≥n: "[texto transcrito]"`
4. El bot debe responder considerando el contenido transcrito

#### Script de Prueba
```bash
node scripts/test-voice-transcription.js
```

Este script prueba:
- Nota de voz normal (type: voice)
- Audio PTT (Push to Talk)
- Audio sin URL (fallback)

### Logs y Monitoreo

Logs generados:
- `AUDIO_TRANSCRIPTION_ERROR` - Error transcribiendo audio
- `AUDIO_NO_URL` - Audio recibido sin URL
- `VOICE_TRANSCRIBED` - Voz transcrita exitosamente
- `VOICE_PROCESSING_ERROR` - Error general en procesamiento
- Console logs con emoji üé§ para identificaci√≥n visual

### Optimizaciones

- Temperatura 0.2 para mayor precisi√≥n
- Prompt contextualizado para hoteles
- Procesamiento as√≠ncrono para no bloquear
- Validaci√≥n de tama√±o antes de descargar

### Tipos de Audio Soportados

1. **voice** - Notas de voz normales
2. **audio** - Archivos de audio
3. **ptt** - Push to Talk (grabaci√≥n r√°pida)

### Casos de Uso

Ideal para:
- Consultas r√°pidas por voz mientras conducen
- Usuarios que prefieren hablar en lugar de escribir
- Mensajes largos o detallados
- Accesibilidad para usuarios con dificultades para escribir

### M√©tricas Rastreadas

- `transcriptionLength` - Longitud del texto transcrito
- `words` - N√∫mero de palabras transcritas
- `lastInputVoice` - Marca para respuestas contextuales

### Troubleshooting

**Problema**: Las notas de voz no se transcriben
- Verifica `ENABLE_VOICE_TRANSCRIPTION=true`
- Confirma que la API key tenga acceso a Whisper
- Revisa el tama√±o del audio (< 25MB)

**Problema**: Transcripciones en ingl√©s
- Verifica `WHISPER_LANGUAGE=es` en .env
- El prompt est√° en espa√±ol para contexto

**Problema**: Errores de timeout
- Audios muy largos pueden causar timeout
- Considera reducir `MAX_AUDIO_DURATION`

**Problema**: Transcripciones imprecisas
- Whisper funciona mejor con audio claro
- Ruido de fondo puede afectar la precisi√≥n

### Pr√≥ximas Etapas

- [x] Etapa 1: Detecci√≥n de Respuestas Citadas
- [x] Etapa 2: Procesamiento de Im√°genes
- [x] Etapa 3: Transcripci√≥n de Voz
- [ ] Etapa 4: Respuestas de Voz