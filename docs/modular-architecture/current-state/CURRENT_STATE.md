ğŸ“¸ Estado Actual del Sistema v2.0

Snapshot exacto y corregido de cÃ³mo funciona el bot, basado en app-unified.ts (3,779 lÃ­neas) al 27 de Julio 2025. Documento actualizado segÃºn anÃ¡lisis y sugerencias para la migraciÃ³n modular.

ğŸ” ARCHIVO PRINCIPAL: app-unified.ts
EstadÃ­sticas:
LÃ­neas: 3,779
Funciones principales: ~92 (distribuidas en ~50 funciones nombradas, ~30 inline/anÃ³nimas en callbacks y ~20 mÃ©todos en terminalLog)
Imports: 30+ mÃ³dulos (incluyendo obsoletos comentados para registro y dinÃ¡micos)
Variables globales: 26+ (Maps, Sets, constantes y objetos para estado, caches y buffers)
Endpoints: 12 rutas Express (7 principales + 4 dashboard + mÃ©tricas + WebSocket)
Estructura Actual (3,779 lÃ­neas):
// IMPORTS (lÃ­neas ~1-150)
import "dotenv/config"; // ConfiguraciÃ³n de entorno
import express, { Request, Response } from 'express'; // Servidor web
import http from 'http'; // CreaciÃ³n de servidor HTTP
import OpenAI from 'openai'; // Cliente OpenAI para Assistant API, TTS, Whisper
import levenshtein from 'fast-levenshtein'; // Distancia de strings (usado en validateAndCorrectResponse)
import path from 'path'; // Manejo de rutas de archivos (temp audio)
import fs from 'fs/promises'; // Operaciones asÃ­ncronas de archivos (audio temporal)

// ConfiguraciÃ³n y utilidades
import { AppConfig, loadAndValidateConfig, logEnvironmentConfig } from './config/environment.js';
import { getConfig } from './config/environment'; // Obsoleto, comentado

// Sistema de logging (~20 funciones)
import {
    logInfo, logSuccess, logError, logWarning, logDebug, logFatal, logAlert,
    // Obsoletos comentados pero importados:
    logMessageReceived, logOpenAIRequest, logOpenAIResponse,
    logFunctionCallingStart, logFunctionExecuting, logFunctionHandler,
    logThreadCreated, logServerStart, logOpenAIUsage, logOpenAILatency,
    logFallbackTriggered, logPerformanceMetrics,
    // Nuevas funciones de tracing:
    logRequestTracing, logToolOutputsSubmitted, logAssistantNoResponse,
    startRequestTracing, updateRequestStage, registerToolCall,
    updateToolCallStatus, endRequestTracing
} from './utils/logging/index.js';

// Persistencia y memoria
import { threadPersistence } from './utils/persistence/index.js';
import { guestMemory } from './utils/persistence/index.js'; // Obsoleto pero importado

// APIs y utilidades externas
import { whapiLabels } from './utils/whapi/index.js';
import type { UserState } from './utils/userStateManager.js';
import { botDashboard } from './utils/monitoring/dashboard.js';
import { validateAndCorrectResponse } from './utils/response-validator.js';

// MÃ©tricas y routing
import metricsRouter, { 
    incrementFallbacks, 
    setTokensUsed, 
    setLatency, 
    incrementMessages 
} from './routes/metrics.js';

// Context y caches
import { cleanupExpiredCaches, getCacheStats } from './utils/context/historyInjection.js';

// Sistema de locks
import { simpleLockManager } from './utils/simpleLockManager.js';

// Function registry (importado dinÃ¡micamente en processWithOpenAI)
// import { executeFunction } from './functions/registry/function-registry.js';
// Se importa con: const { executeFunction } = await import('./functions/registry/function-registry.js');

// VARIABLES GLOBALES (lÃ­neas ~150-400)
let appConfig: AppConfig; // ConfiguraciÃ³n cargada (entorno, secrets)
let openaiClient: OpenAI; // Cliente OpenAI inicializado
let server: http.Server; // Servidor HTTP
let isServerInitialized = false; // Flag de inicializaciÃ³n

// Sistema de logs limpios para terminal (objeto global con ~20 mÃ©todos)
const terminalLog = {
    // Logs principales con formato limpio
    message: (user: string, text: string) => {
        const logMsg = `ğŸ‘¤ ${user}: "${text.substring(0, 60)}${text.length > 60 ? '...' : ''}}"`;
        console.log(logMsg);
        botDashboard.addLog(logMsg);
    },
    typing: (user: string) => console.log(`âœï¸ ${user} estÃ¡ escribiendo...`),
    processing: (user: string) => {}, // Eliminado - no mostrar en terminal
    response: (user: string, text: string, duration: number) => {
        const logMsg = `ğŸ¤– OpenAI â†’ ${user} (${(duration/1000).toFixed(1)}s)`;
        console.log(logMsg);
        botDashboard.addLog(logMsg);
    },
    error: (message: string) => console.log(`âŒ Error: ${message}`),
    openaiError: (user: string, error: string) => console.log(`âŒ Error enviar a OpenAI â†’ ${user}: ${error}`),
    imageError: (user: string, error: string) => console.log(`âŒ Error al procesar imagen â†’ ${user}: ${error}`),
    voiceError: (user: string, error: string) => console.log(`âŒ Error al procesar audio â†’ ${user}: ${error}`),
    functionError: (functionName: string, error: string) => console.log(`âŒ Error en funciÃ³n ${functionName}: ${error}`),
    whapiError: (operation: string, error: string) => console.log(`âŒ Error WHAPI (${operation}): ${error}`),
    functionStart: (name: string, args?: any) => {
        if (name === 'check_availability' && args) {
            const { startDate, endDate } = args;
            const nights = args.endDate && args.startDate ? 
                Math.round((new Date(args.endDate).getTime() - new Date(args.startDate).getTime()) / (1000 * 60 * 60 * 24)) : '?';
            console.log(`âš™ï¸ check_availability(${startDate}-${endDate}, ${nights} noches)`);
        } else {
            console.log(`âš™ï¸ ${name}()`);
        }
    },
    functionProgress: (name: string, step: string, data?: any) => {}, // Eliminado - logs redundantes
    functionCompleted: (name: string, result?: any, duration?: number) => {}, // Se maneja en availabilityResult
    startup: () => {
        console.clear();
        console.log('\n=== Bot TeAlquilamos Iniciado ===');
        console.log(`ğŸš€ Servidor: ${appConfig?.host || 'localhost'}:${appConfig?.port || 3008}`);
        console.log(`ğŸ”— Webhook: ${appConfig?.webhookUrl || 'configurando...'}`);
        console.log('âœ… Sistema listo\n');
    },
    newConversation: (user: string) => console.log(`\nğŸ“¨ Nueva conversaciÃ³n con ${user}`),
    image: (user: string) => console.log(`ğŸ“· ${user}: [Imagen recibida]`),
    voice: (user: string) => {
        const logMsg = `ğŸ¤ ${user}: [Nota de voz recibida]`;
        console.log(logMsg);
        botDashboard.addLog(logMsg);
    },
    recording: (user: string) => console.log(`ğŸ™ï¸ ${user} estÃ¡ grabando...`),
    availabilityResult: (completas: number, splits: number, duration?: number) => {
        const durationStr = duration ? ` (${(duration/1000).toFixed(1)}s)` : '';
        const logMsg = `ğŸ  ${completas} completa${completas !== 1 ? 's' : ''} + ${splits} alternativa${splits !== 1 ? 's' : ''}${durationStr}`;
        console.log(logMsg);
        botDashboard.addLog(logMsg);
    },
    externalApi: (service: string, action: string, result?: string) => {
        const timestamp = new Date().toLocaleTimeString();
        if (result) {
            console.log(`ğŸ”— [${timestamp}] ${service} â†’ ${action} â†’ ${result}`);
        } else {
            console.log(`ğŸ”— [${timestamp}] ${service} â†’ ${action}...`);
        }
    }
};

// Rate limiting y control
const webhookCounts = new Map<string, { lastLog: number; count: number }>(); // Rate limiting logs webhooks
const typingLogTimestamps = new Map<string, number>(); // Rate limiting typing logs (5s)

// Caches con TTL
const chatInfoCache = new Map<string, { data: any; timestamp: number }>(); // Cache info chats
const CHAT_INFO_CACHE_TTL = 5 * 60 * 1000; // 5 minutos
const contextCache = new Map<string, { context: string, timestamp: number }>(); // Cache contexto temporal
const CONTEXT_CACHE_TTL = 60 * 60 * 1000; // 1 hora

// Control de configuraciÃ³n
const SHOW_FUNCTION_LOGS = process.env.TERMINAL_LOGS_FUNCTIONS !== 'false'; // Logs functions en terminal

// Estados y procesamiento
const activeProcessing = new Set<string>(); // Usuarios en procesamiento activo

// Buffer unificado de mensajes
const globalMessageBuffers = new Map<string, {
    messages: string[],
    chatId: string,
    userName: string,
    lastActivity: number,
    timer: NodeJS.Timeout | null,
    currentDelay?: number // Delay actual del timer para comparaciones
}>();
const BUFFER_WINDOW_MS = 5000; // 5 segundos para agrupar mensajes normales
const TYPING_EXTENDED_MS = 10000; // 10 segundos cuando usuario estÃ¡ escribiendo/grabando

// Media y mensajes
const pendingImages = new Map<string, string[]>(); // URLs imÃ¡genes pendientes por usuario
const botSentMessages = new Set<string>(); // IDs de mensajes enviados por bot (evitar self-loops)
const globalUserStates = new Map<string, UserState>(); // Estados de usuario completos

// Control de retries y validaciÃ³n
const userRetryState = new Map<string, { retryCount: number; lastRetryTime: number }>(); // Control retries (evitar loops)
// Cooldown: 5 minutos, LÃ­mite: 1 retry por usuario

// Control de suscripciones a presences
const subscribedPresences = new Set<string>(); // En setupWebhooks, evita resuscripciones duplicadas

// Constantes
const MAX_MESSAGE_LENGTH = 5000; // LÃ­mite longitud mensajes

// Tipos para WHAPI
interface WHAPIMediaLink {
    link?: string;
    id?: string;
    mime_type?: string;
    file_size?: number;
}

interface WHAPIMessage {
    id: string;
    type: string;
    audio?: WHAPIMediaLink;
    voice?: WHAPIMediaLink;
    ptt?: WHAPIMediaLink;
    image?: WHAPIMediaLink;
}

interface WHAPIError {
    error?: {
        code: number;
        message: string;
        details?: string;
    };
}

// FUNCIONES UTILITARIAS (lÃ­neas ~400-2500)

// Helpers bÃ¡sicos (~10 funciones)
function getTimestamp(): string {...}
function getShortUserId(jid: string): string {...}
function cleanContactName(rawName: any): string {...}
function isQuoteOrPriceMessage(message: string): boolean {...}

// GestiÃ³n de estados y caches (~10 funciones)
function getOrCreateUserState(userId: string, chatId?: string, userName?: string): UserState {...}
async function getCachedChatInfo(userId: string): Promise<any> {...}
function invalidateUserCaches(userId: string): void {...}
function getPrecomputedContextBase(): { date: string; time: string } {...}
async function getRelevantContext(userId: string, requestId?: string): Promise<string> {...}

// Media y comunicaciÃ³n (~10 funciones)
async function transcribeAudio(audioUrl: string | undefined, userId: string, userName?: string, messageId?: string): Promise<string> {...}
async function analyzeImage(imageUrl: string | undefined, userId: string, userName?: string, messageId?: string): Promise<string> {...}
async function sendWhatsAppMessage(chatId: string, message: string): Promise<boolean> {...}
async function sendTypingIndicator(chatId: string): Promise<void> {...}
async function sendRecordingIndicator(chatId: string): Promise<void> {...}
async function subscribeToPresence(userId: string): Promise<void> {...}

// Sistema de locks (~5 funciones)
async function acquireThreadLock(userId: string): Promise<boolean> {...}
function releaseThreadLock(userId: string): void {...}

// Buffer y procesamiento (~10 funciones)
function addToGlobalBuffer(userId: string, messageText: string, chatId: string, userName: string, isVoice: boolean = false): void {...}
function setIntelligentTimer(userId: string, chatId: string, userName: string, triggerType: 'message' | 'voice' | 'typing' | 'recording'): void {...}
async function processGlobalBuffer(userId: string): Promise<void> {...}
async function processUserMessages(userId: string): Promise<void> {...}
let processCombinedMessage: (userId: string, combinedText: string, chatId: string, userName: string, messageCount: number) => Promise<void>;

// OpenAI utilities (~10 funciones)
async function cleanupOldRuns(threadId: string, userId: string): Promise<number> {...}
async function isRunActive(userId: string): Promise<boolean> {...}
async function recoverOrphanedRuns(): Promise<void> {...}
async function processWithOpenAI(userMsg: string, userJid: string, chatId: string, userName: string, requestId?: string): Promise<string> {...}

// Setup y configuraciÃ³n (~10 funciones)
function setupEndpoints(): void {...}
function setupSignalHandlers(): void {...}
function setupWebhooks(): void {...}
function initializeBot(): void {...}
async function processWebhook(body: any): Promise<void> {...}

// Funciones inline/anÃ³nimas en intervals y callbacks (~30+)
// - Cleanup intervals (5+)
// - Event handlers (10+)
// - Callback functions (10+)
// - Promise handlers (5+)

// SETUP Y CONFIGURACIÃ“N (lÃ­neas ~2500-3000)
function setupEndpoints(): void {...} // Configura todas las rutas Express
function setupSignalHandlers(): void {
    // Manejo de shutdown graceful
    const shutdown = (signal: string) => {
        logInfo('SHUTDOWN', `SeÃ±al ${signal} recibida`);
        
        // 1. Limpiar todos los timers de buffers
        for (const [userId, buffer] of globalMessageBuffers) {
            if (buffer.timer) clearTimeout(buffer.timer);
        }
        
        // 2. Cerrar servidor HTTP
        if (server) {
            server.close(() => {
                logSuccess('SHUTDOWN', 'Servidor cerrado');
                process.exit(0);
            });
        }
        
        // 3. Timeout forzado despuÃ©s de 5s
        setTimeout(() => {
            logWarning('SHUTDOWN', 'Cierre forzado por timeout');
            process.exit(1);
        }, 5000);
    };
    
    process.on('SIGTERM', () => shutdown('SIGTERM'));
    process.on('SIGINT', () => shutdown('SIGINT'));
}
function setupWebhooks(): void {...} // LÃ³gica webhook y processCombinedMessage
function initializeBot(): void {...} // Intervals, cleanups, recovery

// Procesamiento OpenAI principal
async function processWithOpenAI(
    userMsg: string, 
    userJid: string, 
    chatId: string = null, 
    userName: string = null, 
    requestId?: string
): Promise<string> {
    // 1. Enviar indicador segÃºn tipo de input:
    //    - Si lastInputVoice: sendRecordingIndicator()
    //    - Si no: sendTypingIndicator()
    // 2. Thread management (crear/obtener)
    // 3. subscribeToPresence() SIEMPRE
    // 4. Contexto temporal si necesario
    // 5. Crear content multimodal si hay pendingImages:
    //    content = [
    //      { type: "text", text: messageWithContext },
    //      ...pendingImages.map(url => ({ 
    //        type: "image_url", 
    //        image_url: { url } 
    //      }))
    //    ]
    // 6. Limpiar pendingImages.delete(userId) despuÃ©s de usar
    // 7. Run create, polling, functions, validaciÃ³n
}

// Procesamiento webhook
async function processWebhook(body: any): Promise<void> {...} // Messages, presences, manuales

// SERVIDOR EXPRESS (lÃ­neas ~3000-3500)
const app = express();
app.use(express.json({ limit: '50mb' }));
app.use('/metrics', metricsRouter); // MÃ©tricas Prometheus (incrementFallbacks, setTokensUsed, setLatency, incrementMessages)

// setupEndpoints() configura:
app.get('/health', (req, res) => {...}); // Health check con stats
app.post('/hook', async (req: Request, res: Response) => {
    // 1. Responde 200 inmediatamente (crÃ­tico para evitar timeout Whapi)
    res.status(200).json({ received: true, timestamp: new Date().toISOString() });
    
    // 2. Procesa async en background sin bloquear respuesta
    // 3. Filtra webhooks vÃ¡lidos: messages, presences, statuses, chats, contacts, groups, labels, calls, channel, users
    // 4. Rate limiting para webhooks invÃ¡lidos (1 log/min con webhookCounts Map)
    // 5. Llama processWebhook(req.body) con try/catch para evitar crashes
});
app.get('/', (req, res) => {...}); // Root con info bot
app.get('/locks', (req, res) => {...}); // Monitoreo locks
app.post('/locks/clear', (req, res) => {...}); // Limpia locks (solo dev)
app.get('/audio/:filename', async (req, res) => {
    // ValidaciÃ³n: filename.match(/^voice_\d+_\d+\.(mp3|ogg)$/)
    // Content-Type dinÃ¡mico: 'audio/mpeg' para .mp3, 'audio/ogg; codecs=opus' para .ogg
    // Path: path.join('tmp', 'audio', filename)
    // Verifica existencia con fs.access antes de servir
    // Cache-Control: 'no-cache, no-store, must-revalidate'
});
// botDashboard.setupRoutes(app) configura:
// - /dashboard: UI principal con logs en tiempo real
// - /dashboard/logs: Vista de logs histÃ³ricos
// - /dashboard/stats: EstadÃ­sticas del sistema (threads, memoria, requests)
// - /dashboard/api/logs: WebSocket endpoint para streaming de logs
// - /dashboard/api/stats: JSON API para mÃ©tricas

// MANEJADORES GLOBALES (lÃ­neas ~3500-3700)
process.on('uncaughtException', (error, origin) => {...}); // Log crÃ­tico + exit(1)
process.on('unhandledRejection', (reason, promise) => {...}); // Log crÃ­tico + exit(1)

// FUNCIÃ“N PRINCIPAL (lÃ­neas ~3700-3779)
const main = async () => {
    // 1. Logs iniciales (versiÃ³n Node, memoria, entorno)
    // 2. loadAndValidateConfig() â†’ appConfig
    // 3. logEnvironmentConfig()
    // 4. new OpenAI({ apiKey, timeout, maxRetries })
    // 5. setupEndpoints() â†’ todas las rutas
    // 6. setupWebhooks() â†’ lÃ³gica procesamiento
    // 7. http.createServer(app) â†’ server.listen()
    // 8. initializeBot() â†’ cleanups, intervals, recovery
    // 9. setupSignalHandlers() â†’ shutdown graceful
    // 10. Catch: servidor mÃ­nimo si falla (puerto 8080)
};

main();


ğŸ”„ FLUJO DE PROCESAMIENTO ACTUAL
1. RecepciÃ³n de Webhook (processWebhook):
WhatsApp â†’ Whapi â†’ POST /hook â†’ Respuesta 200 inmediata â†’ processWebhook(body) async
                                                    â†“
                                    Validar body (messages/presences/event)
                                                    â†“
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ PRESENCES (typing/recording):                           â”‚
                    â”‚ - Actualizar userState.lastTyping = Date.now()         â”‚
                    â”‚ - setIntelligentTimer(10s extended)                    â”‚
                    â”‚ - terminalLog.typing/recording (rate limited 5s)       â”‚
                    â”‚ - Si status online/offline: limpiar isCurrentlyRecordingâ”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                    â†“
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ MESSAGES:                                               â”‚
                    â”‚ 1. Filtrar from_me:                                     â”‚
                    â”‚    - Si botSentMessages.has(id): skip                  â”‚
                    â”‚    - Si manual real: buffer especial + sync thread     â”‚
                    â”‚ 2. Por tipo:                                           â”‚
                    â”‚    - Voice: transcribeAudio â†’ ğŸ¤ + texto               â”‚
                    â”‚    - Image: analyzeImage â†’ ğŸ“· + descripciÃ³n (opcional) â”‚
                    â”‚    - Text: ğŸ“ + texto                                  â”‚
                    â”‚ 3. addToGlobalBuffer() con metadata                    â”‚
                    â”‚ 4. setIntelligentTimer (5-10s segÃºn tipo)             â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


2. Procesamiento de Buffer (processGlobalBuffer):
Timer expira (5-10s) â†’ processGlobalBuffer(userId)
                              â†“
        Verificar typing reciente (<10s) y msgs.length === 1
                              â†“ Si sÃ­
                    Retrasar remainingTime (hasta 10s desde lastTyping)
                              â†“ Si no
                    Verificar activeProcessing.has(userId)
                              â†“ Si no
                    Marcar activeProcessing.add(userId)
                              â†“
                    Copiar mensajes y limpiar buffer.messages = []
                              â†“
                    Combinar mensajes con '\n'
                              â†“
                    processCombinedMessage(userId, combinedText, ...)
                              â†“
                    activeProcessing.delete(userId) en finally


3. LÃ³gica de OpenAI (processCombinedMessage + processWithOpenAI):
processCombinedMessage(userId, combinedText, ...)
                    â†“
        isRunActive() con cleanupOldRuns previo
                    â†“ Si active
        Retry hasta 3 veces (1s delay) o cancelar requires_action
                    â†“
        simpleLockManager.addToQueue(userId, messageId, data, processFunction)
                    â†“
        processFunction():
            â†“
        startRequestTracing(userId) â†’ updateRequestStage('init')
            â†“
        getRelevantContext() si necesario:
            - Condiciones: 3h desde Ãºltimo, cambio nombre/labels, primer mensaje
            - Si cambio detectado (nombre/labels):
                â”œâ”€ invalidateUserCaches(userId) // Limpia caches obsoletos
                â””â”€ threadPersistence.updateThreadMetadata() // Actualiza metadata
            - Genera contexto temporal con fecha/hora/cliente/labels
            â†“
        processWithOpenAI(combinedText, userId, chatId, userName, requestId)
            â”œâ”€ sendTypingIndicator() o sendRecordingIndicator() segÃºn lastInputVoice
            â”œâ”€ Crear/obtener thread (threadPersistence)
            â”œâ”€ subscribeToPresence(shortUserId) SIEMPRE (no solo new threads)
            â”œâ”€ Agregar mensaje con contexto temporal
            â”œâ”€ Adjuntar pendingImages si existen como content multimodal
            â”œâ”€ openaiClient.beta.threads.runs.create()
            â”œâ”€ Polling (1s interval, max 30 attempts, backoff en race conditions)
            â”œâ”€ Si completed: obtener respuesta
            â”œâ”€ Si requires_action:
            â”‚   â”œâ”€ Mensaje interino si check_availability complejo
            â”‚   â”œâ”€ executeFunction() para cada tool call
            â”‚   â”‚   â””â”€ registerToolCall() â†’ updateToolCallStatus()
            â”‚   â”œâ”€ submitToolOutputs
            â”‚   â””â”€ Polling post-tool (500ms-5s backoff, max 10)
            â”œâ”€ validateAndCorrectResponse()
            â”‚   â””â”€ Si needsRetry: correctiveMessage + retry run (userRetryState)
            â””â”€ Si context_length_exceeded: crear thread nuevo
                    â†“
        sendWhatsAppMessage(chatId, response)
            â”œâ”€ Si lastInputVoice && !sensible: TTS nova â†’ voice message
            â”œâ”€ Si sensible (precios/enlaces): forzar texto
            â””â”€ DivisiÃ³n inteligente en pÃ¡rrafos con typing_time
                    â†“
        endRequestTracing() + mÃ©tricas (tokens, latency)


4. Flujos Especiales:
Mensajes Manuales (from_me: true):
Webhook detecta from_me: true â†’ Verificar NO es botSentMessages.has(id)
    â†“ Si es manual real
Buffer separado en globalMessageBuffers con key=chatId
    â†“
Timer 5s (BUFFER_WINDOW_MS) â†’ Agrupar mÃºltiples mensajes
    â†“
Procesar buffer:
    1. Crear mensaje de contexto del sistema:
       await threads.messages.create(threadId, {
         role: 'user',
         content: '[Mensaje manual de {agentName}]'
       })
    2. Agregar contenido real como assistant:
       await threads.messages.create(threadId, {
         role: 'assistant', 
         content: combinedMessage  // Mensajes agrupados
       })
    â†“
threadPersistence.setThread() actualiza metadata
Log: MANUAL_SYNC_SUCCESS con preview y stats


Media Handling:
Voice â†’ transcribeAudio():
    - Verificar audioUrl o fetch desde WHAPI usando messageId
    - Descargar audio con fetch â†’ arrayBuffer
    - Crear temp file: path.join('tmp', `audio_${Date.now()}.ogg`)
    - fs.writeFile(tempPath, Buffer.from(audioBuffer))
    - createReadStream para OpenAI Whisper
    - OpenAI transcription con model='whisper-1', language='es'
    - Cleanup con manejo de errores:
      await fs.unlink(tempPath).catch((err) => {
        logWarning('TEMP_FILE_CLEANUP', 'Error eliminando archivo temporal', { 
          file: tempPath, 
          error: err.message 
        });
      });
    - Retornar transcripciÃ³n o 'No se pudo transcribir el audio'
    - Si error: terminalLog.voiceError(displayName, error.message) y throw

Image â†’ pendingImages:
    - Extraer URL de message.image?.link
    - Si no hay URL, fetch desde WHAPI similar a voice
    - pendingImages.get(userId).push(imageUrl)
    - Al procesar con OpenAI:
      content: [
        { type: "text", text: messageWithContext },
        { type: "image_url", image_url: { url: imageUrl }}
      ]
    - Limpiar pendingImages.delete(userId) post-uso


Voice Responses con Fallback Inteligente:
Si lastInputVoice === true && ENABLE_VOICE_RESPONSES === 'true':
    â†“
Verificar contenido sensible con isQuoteOrPriceMessage():
    - Regex patterns:
      /\$\d+[.,]?\d*/g              // $840.000
      /\d+[.,]?\d*\s*(cop|pesos?)/gi // 840000 COP
      /\d+\s*noches?/gi             // 4 noches
      /https?:\/\/\S+/i             // URLs
      /wa\.me\/p/i                  // Enlaces WhatsApp
    â†“ Si match â†’ Forzar texto (shouldUseVoice = false)
    
Si shouldUseVoice:
    - OpenAI TTS: model='tts-1', voice='nova', max 4000 chars
    - Convertir response a arrayBuffer â†’ Buffer â†’ base64
    - Crear data URL: `data:audio/mp3;base64,${base64Audio}`
    - POST a Whapi /messages/voice con media: dataUrl
    - Si OK: limpiar userState.lastInputVoice = false
    - Si error: fallback a texto normal
    
EnvÃ­o de texto (normal o fallback):
    - DivisiÃ³n inteligente por pÃ¡rrafos (\n\n+)
    - O por listas con bullets (â€¢, -, *)
    - typing_time: 3s primer msg, 2s siguientes
    - Guardar en botSentMessages.add(responseId)
    - Auto-delete despuÃ©s de 10 min


AnÃ¡lisis de ImÃ¡genes con Vision:
Usuario envÃ­a imagen â†’ Webhook detecta type: 'image'
    â†“
analyzeImage(imageUrl, userId, userName, messageId):
    - Si no hay URL, fetch desde WHAPI /messages/{messageId}
    - Validar URL comienza con 'http'
    - OpenAI Vision con GPT-4o-mini:
      messages: [{
        role: 'user',
        content: [
          { type: 'text', text: 'Analiza esta imagen en contexto hotelero...' },
          { type: 'image_url', image_url: { url: finalUrl, detail: 'low' }}
        ]
      }]
    - max_tokens: 150, temperature: 0.3
    - Retorna descripciÃ³n breve (max 100 palabras)
    - Si error: terminalLog.imageError() y throw
    â†“
pendingImages.get(userId).push(imageUrl)
    â†“
Al procesar con OpenAI:
    - Adjuntar como content multimodal
    - Limpiar pendingImages.delete(userId) despuÃ©s


SuscripciÃ³n a Presences (Siempre Activa):
processWithOpenAI() â†’ DespuÃ©s de crear/obtener thread
    â†“
subscribeToPresence(shortUserId):
    - Verificar subscribedPresences.has(userId)
    - Si ya suscrito: return (evita duplicados)
    - POST /presences/{userId} sin body
    - Si 200: subscribedPresences.add(userId)
    - Si 409: TambiÃ©n add (ya estaba suscrito)
    - Si error: Log pero continuar (no crÃ­tico)
    â†“
Usuario ahora envÃ­a eventos typing/recording automÃ¡ticamente


5. Cleanup y Recovery:
AL BOOT:
    - threadPersistence.initializeCleanup()
    - recoverOrphanedRuns() en background (5s delay)
        â””â”€ Cancelar TODOS los runs activos

INTERVALS:
    - cleanupExpiredCaches() cada 10 min
    - Memory logs cada 5 min (alert si >300MB o >95% heap)
    - User states cleanup cada 1h (>24h inactivo)
    - Global buffer cleanup cada 10 min (>15 min inactivo)
    
SHUTDOWN (SIGTERM/SIGINT):
    - Clear todos los timers
    - server.close() con timeout 5s
    - Logs de shutdown detallados


6. Sistema de Tracing:
startRequestTracing(userId) â†’ requestId
    â†“
updateRequestStage(requestId, 'init'|'processing'|'function_calling'|'completed')
    â†“
registerToolCall(requestId, toolCallId, functionName, 'executing')
    â†“
updateToolCallStatus(requestId, toolCallId, 'success'|'error')
    â†“
endRequestTracing(requestId) â†’ summary con duraciÃ³n total


ğŸ—„ï¸ DATOS QUE MANEJA
En Memoria (VolÃ¡til con TTLs):
// BUFFERS Y ESTADOS
globalMessageBuffers: Map<string, {
    messages: string[],        // Hasta 50 msgs
    chatId: string,
    userName: string,
    lastActivity: number,      // Para cleanup >15min
    timer: NodeJS.Timeout | null,
    currentDelay?: number      // 5000ms normal, 10000ms si typing/recording activo
}>

globalUserStates: Map<string, UserState> {
    userId: string,
    isTyping: boolean,
    lastTypingTimestamp: number,
    lastMessageTimestamp: number,
    messages: string[],
    chatId: string,
    userName: string,
    typingEventsCount: number,
    averageTypingDuration: number,
    lastInputVoice: boolean,   // Para voice responses
    lastTyping: number,        // Ãšltimo typing detectado
    isCurrentlyRecording?: boolean
}

// CACHES CON TTL
contextCache: Map<string, {    // TTL: 1 hora
    context: string,           // Contexto temporal formateado
    timestamp: number
}>

chatInfoCache: Map<string, {   // TTL: 5 minutos
    data: any,                 // Info de Whapi (name, labels)
    timestamp: number
}>

// CONTROL Y RATE LIMITING
activeProcessing: Set<string>  // Durante procesamiento

botSentMessages: Set<string>   // TTL: 10 minutos auto-delete
                              // IDs para evitar self-loops

userRetryState: Map<string, {  // Control retries validaciÃ³n
    retryCount: number,        // Max 1 retry
    lastRetryTime: number      // Cooldown 5 minutos
}>

pendingImages: Map<string, string[]>  // URLs por usuario
// Se adjuntan a OpenAI como content multimodal:
// [{ type: "text", text: msg }, { type: "image_url", image_url: { url } }]

webhookCounts: Map<string, {   // Rate limiting logs
    lastLog: number,
    count: number
}>

typingLogTimestamps: Map<string, number>  // Rate limit 5s

// CACHE TEMPORAL
precomputedContextBase: {      // TTL: 1 minuto
    date: string,
    time: string,
    timestamp: number
} | null


En Archivos JSON (Persistente):
// threads-data.json (via threadPersistence)
{
  "573001234567": {
    "threadId": "thread_abc123",
    "chatId": "573001234567@s.whatsapp.net",
    "userName": "Juan PÃ©rez",
    "createdAt": "2025-07-27T10:30:00Z",
    "lastActivity": "2025-07-27T15:45:00Z",
    "name": "Juan PÃ©rez",         // Para detectar cambios
    "labels": ["Consulta", "VIP"]  // Para detectar cambios
  }
}

// guest-memory.json (obsoleto pero aÃºn importado)
{
  "573001234567": {
    "name": "Juan PÃ©rez",
    "whapiLabels": [
      {"id": "1", "name": "Potencial"},
      {"id": "2", "name": "Consulta"}
    ],
    "lastInteraction": "2025-07-27T15:45:00Z"
  }
}


Archivos Temporales:
/tmp/
â”œâ”€â”€ audio_1234567890.ogg    // TranscripciÃ³n Whisper (deleted post-uso)
â”œâ”€â”€ audio_1234567891.mp3    // TTS output (deleted post-envÃ­o)
â””â”€â”€ ...

âš ï¸ Riesgo: Si fs.unlink() falla, archivos se acumulan
MitigaciÃ³n actual: .catch(() => {}) ignora errores
Problema: No hay cleanup periÃ³dico de /tmp/


ğŸ¨ FUNCIONALIDADES ESPECÃFICAS DE HOTELERÃA
Check Availability Function:
// Registrada en function-registry.js
{
    name: "check_availability",
    description: "Verificar disponibilidad y precios en el sistema",
    parameters: {
        type: "object",
        properties: {
            startDate: { type: "string", description: "YYYY-MM-DD" },
            endDate: { type: "string", description: "YYYY-MM-DD" },
            guests: { type: "number", default: 2 }
        }
    }
}

// EjecuciÃ³n:
executeFunction("check_availability", args) â†’
    - Calcular noches
    - Llamar Beds24 API (JSON endpoint)
    - Parsear respuesta XML
    - Aplicar timezone America/Bogota
    - Formatear: completas (disponibles) + splits (alternativas)
    - terminalLog.availabilityResult(completas, splits, duration)


Labels Hoteleros:
// Via whapiLabels y getCachedChatInfo
Etiquetas disponibles: [
    'Potencial',      // Cliente interesado
    'Consulta',       // En proceso de cotizaciÃ³n
    'Reservado',      // ConfirmÃ³ reserva
    'VIP',           // Cliente especial
    'Check-in',      // En hotel
    'Check-out',     // SaliÃ³ del hotel
    'Cancelado',     // CancelÃ³ reserva
    'Repetidor'      // Cliente recurrente
]


Contexto Temporal:
// Inyectado automÃ¡ticamente cada 3h o al cambiar datos
`Fecha: 27/07/2025 | Hora: 10:30 AM (Colombia)
Cliente: Juan PÃ©rez | Contacto WhatsApp: Juan | Status: Consulta, VIP
---
Mensaje del cliente:`


ValidaciÃ³n y CorrecciÃ³n:
DetecciÃ³n sensible: Regex para $, COP, precios, URLs (fallback voiceâ†’text)
ValidaciÃ³n respuestas: levenshtein distance para discrepancias
CorrecciÃ³n: Manual o retry automÃ¡tico con correctiveMessage
Timezone: Todas las fechas/horas en America/Bogota

âš¡ PERFORMANCE ACTUAL
MÃ©tricas TÃ­picas:
Tiempo respuesta promedio: 3-8s (OpenAI 1-5s + Beds24 2-5s)
Memoria RAM: 150-400MB (alertas >300MB, crÃ­tico >95% heap)
CPU: 10-40% en picos (TTS/Whisper intensive)
Usuarios concurrentes: 50-200 tÃ­pico, mÃ¡x 500
Requests/min: 200-1000 (webhooks + API calls)
Tokens/request: 500-3000 (alertas >2000)
Bottlenecks Identificados:
OpenAI Polling: 1-3s base + backoff (puede llegar a 30s timeout)
Beds24 API: 2-5s tÃ­pico, ~20% timeouts
Transcripciones Audio: 3-10s (descarga + Whisper + temp file)
TTS Generation: 2-5s para respuestas largas
Memory Growth: Caches sin lÃ­mite estricto (mitigado con intervals)
Memory Leaks Potenciales:
globalMessageBuffers: Timers no cancelados en race conditions
contextCache/chatInfoCache: Crecimiento sin lÃ­mite mÃ¡ximo
globalUserStates: Cleanup cada hora pero puede acumular
pendingImages: No tiene TTL explÃ­cito
Temp files: Si fs.unlink falla, acumulaciÃ³n en /tmp
ğŸ”Œ INTEGRACIONES EXTERNAS
OpenAI Assistant API:
Endpoint: https://api.openai.com/v1
Assistant ID: process.env.OPENAI_ASSISTANT_ID
Models:
  - whisper-1: TranscripciÃ³n audio (espaÃ±ol)
  - tts-1: Text-to-speech (voice: nova)
  - gpt-4: Assistant principal
Functions disponibles:
  - check_availability
  - get_conversation_context
  - view_image
  - search_knowledge
Rate limits: 
  - Timeout: configurable en appConfig
  - Retries: configurable en appConfig
Manejo errores:
  - context_length_exceeded â†’ Nuevo thread automÃ¡tico
  - Runs huÃ©rfanos â†’ Cleanup automÃ¡tico
  - Race conditions â†’ Backoff progresivo


Whapi Cloud:
Endpoint: ${WHAPI_API_URL} (e.g., https://gate.whapi.cloud/)
Token: ${WHAPI_TOKEN}
Endpoints usados:
  - /messages/text: Enviar mensajes texto
  - /messages/voice: Enviar notas de voz
  - /presences/{id}: Suscribir/actualizar presencia
  - /messages/{id}: Obtener info mensaje (media URLs)
  - /chats/{id}: Obtener info chat
Funcionalidades:
  - Labels management
  - Presences (typing, recording, online)
  - Media handling (images, voice)
Rate limits: No documentado
Webhooks: POST /hook


Beds24 API:
Endpoint: https://beds24.com/api/json/
Auth: 
  - apiKey: En secrets
  - propKey: En secrets
Endpoints:
  - getAvailabilities: Disponibilidad y precios
Response: XML (parseado a JSON)
Timezone: UTC â†’ America/Bogota
Rate limits: No documentado
Timeouts: ~20% de requests
Formato respuesta:
  - roomId, units available
  - prices por noche
  - min stay requirements


ğŸ› ï¸ SISTEMAS AUXILIARES
Sistema de Logging (terminalLog):
// Objeto con ~20 mÃ©todos para logs limpios
terminalLog = {
    // Mensajes bÃ¡sicos
    message(user, text): "ğŸ‘¤ user: text..."
    typing(user): "âœï¸ user estÃ¡ escribiendo..."
    response(user, text, duration): "ğŸ¤– OpenAI â†’ user (Xs)"
    
    // Errores especÃ­ficos
    error(message): "âŒ Error: message"
    openaiError(user, error): "âŒ Error enviar a OpenAI â†’ user"
    imageError(user, error): "âŒ Error al procesar imagen â†’ user"
    voiceError(user, error): "âŒ Error al procesar audio â†’ user"
    functionError(name, error): "âŒ Error en funciÃ³n name"
    whapiError(operation, error): "âŒ Error WHAPI (operation)"
    
    // Function calling
    functionStart(name, args): "âš™ï¸ name(args)"
    functionCompleted(name, result, duration): Log segÃºn funciÃ³n
    availabilityResult(completas, splits, duration): "ğŸ  X completas + Y alternativas (Xs)"
    
    // Sistema
    startup(): Clear + banner inicial
    newConversation(user): "ğŸ“¨ Nueva conversaciÃ³n con user"
    image(user): "ğŸ“· user: [Imagen recibida]"
    voice(user): "ğŸ¤ user: [Nota de voz recibida]"
    recording(user): "ğŸ™ï¸ user estÃ¡ grabando..."
    externalApi(service, action, result): "ğŸ”— [timestamp] service â†’ action"
}


Sistema de Locks (simpleLockManager):
// Sistema hÃ­brido con locks y colas por usuario
ConfiguraciÃ³n:
    - Tipo: user-based (un lock por userId)
    - Timeout: 15 segundos (auto-release si no se libera)
    - Queue: habilitada (procesa en orden FIFO)
    - Auto-release: sÃ­ (previene deadlocks)
    - Concurrencia: 1 proceso por usuario a la vez
    
MÃ©todos principales:
    - acquireUserLock(userId): Promise<boolean>
      â””â”€ Intenta adquirir lock, retorna true si Ã©xito
    - releaseUserLock(userId): void
      â””â”€ Libera lock y procesa siguiente en cola
    - addToQueue(userId, messageId, data, processFunction): void
      â””â”€ Agrega a cola si lock ocupado
    - processQueue(userId): Promise<void>
      â””â”€ Procesa items en cola secuencialmente
    - hasActiveLock(userId): boolean
      â””â”€ Verifica si usuario tiene lock activo
    - getStats(): {activeLocks: number, activeQueues: number}
      â””â”€ EstadÃ­sticas del sistema
    - clearAll(): void
      â””â”€ Limpia todos los locks (solo desarrollo)

Uso en el flujo:
    1. processCombinedMessage intenta acquireThreadLock
    2. Si ocupado â†’ addToQueue con processFunction
    3. Al terminar â†’ releaseThreadLock
    4. Auto-procesa siguiente en cola


Sistema de Tracing:
// Request lifecycle tracking
Funciones:
    - startRequestTracing(userId): string (requestId)
    - updateRequestStage(requestId, stage): void
    - registerToolCall(requestId, toolCallId, name, status): void
    - updateToolCallStatus(requestId, toolCallId, status): void
    - endRequestTracing(requestId): TracingSummary
    
Stages: init â†’ processing â†’ function_calling â†’ post_tools_completed â†’ completed
Tool status: executing â†’ success|error


ğŸš¨ PROBLEMAS CONOCIDOS
CrÃ­ticos:
Memory leaks sin mitigaciÃ³n completa
   - Caches crecen indefinidamente si cleanup intervals fallan
   - Causa crashes en Cloud Run tras ~24h de uptime
   - contextCache/chatInfoCache sin lÃ­mite mÃ¡ximo de entradas
   - globalUserStates puede acumular miles de usuarios
   - MitigaciÃ³n actual: Restart diario manual
Persistencia no escalable
   - JSON files para threads (I/O blocking)
   - PÃ©rdida de memoria/estados al reiniciar
   - No soporta mÃºltiples instancias
CÃ³digo monolÃ­tico inmantenible
   - 3,779 lÃ­neas en un archivo
   - Funciones dispersas sin organizaciÃ³n clara
   - Imports obsoletos comentados por todas partes
Runs huÃ©rfanos facturaciÃ³n extra
   - Si cleanup falla, runs activos indefinidos
   - Costo adicional OpenAI (~$0.03/run abandonado)
Altos:
Beds24 API inestable
   - ~20% timeouts sin retry automÃ¡tico
   - Afecta UX en cotizaciones
   - Sin circuit breaker
Voice handling frÃ¡gil
   - Transcripciones fallan si no hay URL
   - TTS limitado a 4000 caracteres
   - Temp files pueden acumular si cleanup falla
ValidaciÃ³n puede causar loops
   - userRetryState mitiga pero no elimina
   - Errores complejos no siempre corregibles
   - Puede agotar tokens rÃ¡pidamente
Webhook processing sin deduplicaciÃ³n
   - Mensajes duplicados procesados mÃºltiples veces
   - Rate limiting solo en logs, no en procesamiento
Medios:
Sin tests automatizados
   - Cambios rompen flujos sin detecciÃ³n
   - Regresiones frecuentes en buffers/timers
Logs excesivamente verbosos
   - ~100 logs por request en modo debug
   - Dificulta debugging real en producciÃ³n
MÃ©tricas incompletas
   - No tracking de memory leaks especÃ­ficos
   - No histogramas de latencia
   - No alertas automÃ¡ticas configuradas
ConfiguraciÃ³n mezclada local/cloud
   - Riesgo de usar config incorrecta
   - Secrets en .env no rotados
Dashboard bÃ¡sico
   - Solo logs en tiempo real
   - No histÃ³ricos ni analytics
   - No filtros avanzados
ğŸ“Š MÃ‰TRICAS Y MONITOREO
Endpoints de Monitoreo:
/health: Status general + thread stats
/metrics: MÃ©tricas Prometheus (fallbacks, tokens, latency)
/locks: Estado del sistema de locks
/dashboard: UI web con logs en tiempo real
/: Info general del bot
MÃ©tricas Trackeadas:
Messages procesados (incrementMessages)
Fallbacks OpenAI (incrementFallbacks)
Tokens usados (setTokensUsed)
Latencia requests (setLatency)
Memory usage (cada 5min)
Active threads/buffers
Documento generado el 27 de Julio 2025 - VersiÃ³n 2.0.0-corrected
ğŸ“ NOTA IMPORTANTE PARA MIGRACIÃ“N
Este documento es crÃ­tico para la migraciÃ³n modular. Cualquier funcionalidad no documentada aquÃ­ corre el riesgo de perderse durante la refactorizaciÃ³n. Verificar contra el cÃ³digo fuente completo antes de iniciar la migraciÃ³n.
Riesgos CrÃ­ticos Identificados:
subscribedPresences no migrado puede causar spam de suscripciones WHAPI.
analyzeImage no integrado romperÃ¡ procesamiento de imÃ¡genes hoteleras.
Imports dinÃ¡micos (function-registry) mal configurados causarÃ¡n errores en runtime.
Cooldown de retries (userRetryState) debe mantenerse para evitar loops costosos.
Timestamp fix en runs es crÃ­tico o se cancelarÃ¡n todos los runs por error de cÃ¡lculo.
Manejo de mensajes manuales (from_me) es vital para la sincronizaciÃ³n con agentes.
Checklist Pre-MigraciÃ³n:
[ ] Verificar que todos los Maps/Sets (userRetryState, subscribedPresences, etc.) tengan estrategia de migraciÃ³n.
[ ] Confirmar que todos los timers (globalMessageBuffers) se manejen correctamente en mÃ³dulos.
[ ] Asegurar que botSentMessages se migre para evitar self-loops.
[ ] Validar que el cleanup de temp files (/tmp/audio_*) funcione en la nueva arquitectura.
[ ] Probar que invalidateUserCaches funcione entre mÃ³dulos para mantener consistencia.
[ ] Verificar que el sistema de locks (simpleLockManager) mantenga su integridad.
[ ] Migrar la lÃ³gica de subscribeToPresence para que siga activa en cada procesamiento.
[ ] Asegurar que analyzeImage se integre con el nuevo sistema de manejo de media.
[ ] Mantener la lÃ³gica de isQuoteOrPriceMessage para el fallback de voz a texto.
[ ] Probar el flujo completo de mensajes manuales (from_me: true).


::::::::::

AGREGADO NUEVO

De acuerdo. A continuaciÃ³n, se redactan las secciones faltantes y las mejoras sugeridas para ser integradas directamente en el documento **"Estado Actual del Sistema v2.0"**, completando asÃ­ la documentaciÃ³n de manera exhaustiva.

-----

### **(SecciÃ³n Nueva para Agregar al Documento)**

### âš™ï¸ ConfiguraciÃ³n y Variables de Entorno

El comportamiento del bot se controla a travÃ©s de variables de entorno, que deben ser definidas en un archivo `.env` para desarrollo local o configuradas en el entorno de despliegue (e.g., Cloud Run).

| Variable | DescripciÃ³n | Valor por Defecto/Ejemplo | Criticidad |
| :--- | :--- | :--- | :--- |
| `OPENAI_ASSISTANT_ID` | ID del Asistente de OpenAI que orquesta las respuestas y funciones. | `asst_xxxxxxxxxxxxxxxx` | **CrÃ­tica** |
| `WHAPI_API_URL` | URL base de la API de Whapi Cloud. | `https://gate.whapi.cloud` | **CrÃ­tica** |
| `WHAPI_TOKEN` | Token de autorizaciÃ³n para la API de Whapi Cloud. | `xxxxxxxxxxxxxxxxxxxxxx` | **CrÃ­tica** |
| `ENABLE_VOICE_TRANSCRIPTION` | Si es `true`, las notas de voz se transcriben usando Whisper. | `true` | Alta |
| `ENABLE_VOICE_RESPONSES` | Si es `true`, el bot responderÃ¡ con notas de voz si el Ãºltimo input del usuario fue por voz. | `true` | Media |
| `IMAGE_ANALYSIS_MODEL` | Modelo de OpenAI Vision a utilizar para el anÃ¡lisis de imÃ¡genes. | `gpt-4o-mini` | Media |
| `TERMINAL_LOGS_FUNCTIONS` | Si es `false`, se ocultan los logs detallados de ejecuciÃ³n de funciones en la terminal para reducir el ruido. | `true` | Baja |
| `NODE_ENV` | Define el entorno de ejecuciÃ³n. Afecta la carga de configuraciÃ³n. | `development` | Alta |
| `PORT` | Puerto en el que se ejecutarÃ¡ el servidor Express. | `3008` | Alta |

-----

### **(SecciÃ³n Nueva para Agregar al Documento)**

### ğŸ§ª Estrategia de Testing

Para garantizar la estabilidad y prevenir regresiones, el sistema estÃ¡ diseÃ±ado para ser testeable. Al final del archivo `app-unified.ts` se exportan funciones clave para poder ejecutar pruebas unitarias y de integraciÃ³n.

**Funciones Exportadas para Testing:**

  * `getShortUserId`, `cleanContactName`, `isQuoteOrPriceMessage`: Funciones utilitarias puras.
  * `getCachedChatInfo`, `invalidateUserCaches`: Para probar la lÃ³gica de cache.
  * `transcribeAudio`, `analyzeImage`: Para mockear las APIs de OpenAI y probar el manejo de media.
  * `processWebhook`: Para simular eventos de Whapi y probar el flujo de entrada completo.

**Framework Sugerido:** Se recomienda el uso de **Vitest** o **Jest** para la ejecuciÃ³n de tests. Las pruebas deben mockear las dependencias externas (OpenAI, Whapi, Beds24) para aislar la lÃ³gica interna del bot y validar su comportamiento de forma predecible.

-----

### **(SecciÃ³n Actualizada para Reemplazar en el Documento)**

### ğŸš¨ PROBLEMAS CONOCIDOS Y ESTRATEGIAS DE MITIGACIÃ“N

| Problema Conocido | Riesgo | MitigaciÃ³n Propuesta para la MigraciÃ³n Modular |
| :--- | :--- | :--- |
| **Memory Leaks Potenciales** | Crecimiento indefinido de caches (`contextCache`, `globalUserStates`) y buffers puede causar crashes en entornos con memoria limitada como Cloud Run. | **Implementar lÃ­mites estrictos** en todos los caches (e.g., `max: 1000` entradas) usando una librerÃ­a como `lru-cache`. **Crear un mÃ³dulo `CacheManager`** centralizado. |
| **AcumulaciÃ³n de Temp Files** | Si `fs.unlink()` falla silenciosamente (`.catch(()=>{})`), el disco en `/tmp/` se llenarÃ¡ con archivos de audio, causando un fallo del servicio. | **Crear un `cleanupService`** que se ejecute periÃ³dicamente (e.g., cada hora) y elimine todos los archivos en `/tmp/audio/` con mÃ¡s de 60 minutos de antigÃ¼edad. |
| **Persistencia No Escalable** | El uso de archivos JSON para `threadPersistence` causa I/O blocking y no permite escalar a mÃºltiples instancias del bot. | **Migrar la persistencia a una base de datos externa**. **Redis** es ideal para la gestiÃ³n de threads y estados volÃ¡tiles con TTL. **Firestore/MongoDB** para una persistencia mÃ¡s robusta. |
| **CÃ³digo MonolÃ­tico Inmantenible** | 3,779 lÃ­neas en un solo archivo dificultan el desarrollo, la depuraciÃ³n y la incorporaciÃ³n de nuevas funcionalidades. | **El objetivo principal de la migraciÃ³n**. Refactorizar el cÃ³digo en mÃ³dulos por dominio: `webhook`, `openai`, `whatsapp`, `state`, `functions`, `core`, etc. |
| **API de Beds24 Inestable** | \~20% de timeouts sin un mecanismo de reintento automÃ¡tico, afectando directamente la experiencia del usuario al solicitar cotizaciones. | **Implementar un patrÃ³n de `Retry` con `Exponential Backoff`** para las llamadas a la API de Beds24. AÃ±adir un **`Circuit Breaker`** para dejar de intentar si la API estÃ¡ caÃ­da. |
| **Procesamiento de Webhook sin DeduplicaciÃ³n** | Whapi puede enviar webhooks duplicados. Actualmente, el sistema los procesarÃ­a mÃºltiples veces, generando respuestas y costos duplicados. | **Implementar un cache de IDs de mensajes procesados**. Antes de procesar un mensaje, verificar si su ID ya existe en un `Set` o `Cache` con un TTL de \~5 minutos. |
| **Loops en ValidaciÃ³n de Respuestas** | El mecanismo de reintento con `correctiveMessage` es poderoso pero puede entrar en loops si la IA no logra corregir sus errores. | El `userRetryState` (1 reintento cada 5 min) es una buena mitigaciÃ³n. **Reforzarlo** asegurando que el `correctiveMessage` sea cada vez mÃ¡s especÃ­fico o aÃ±adiendo un contador global para desactivar reintentos si falla repetidamente. |

-----

### **(SecciÃ³n Actualizada para Reemplazar en el Documento)**

### ğŸ¨ FUNCIONALIDADES ESPECÃFICAS DE HOTELERÃA

... (contenido existente) ...

### ğŸ”Œ INTEGRACIONES EXTERNAS

... (contenido existente) ...

### ğŸ› ï¸ SISTEMAS AUXILIARES

... (contenido existente) ...

### **(SecciÃ³n Nueva para Agregar al Documento)**

### ğŸ“Š Diagramas de Flujo del Sistema

#### Flujo 1: SincronizaciÃ³n de Mensajes Manuales (`from_me: true`)

Este flujo es crÃ­tico para mantener el contexto del Asistente cuando un agente humano interviene en la conversaciÃ³n.

```ascii
[Agente envÃ­a msg en WhatsApp]
           |
           v
[POST /hook] -> (from_me: true, NO es de botSentMessages)
           |
           v
[globalMessageBuffers] -> (Agrupa mensajes del agente por 5s)
           |
           v
[Timer expira] -> (Procesa buffer del agente)
           |
           +-------------------------------------------------------------+
           |                                                             |
           v                                                             v
[OpenAI API] -> threads.messages.create()           [OpenAI API] -> threads.messages.create()
  (Paso 1: AÃ±adir contexto del sistema)               (Paso 2: AÃ±adir msg real como 'assistant')
  - role: 'user'                                      - role: 'assistant'
  - content: "[Mensaje manual de Agente]"             - content: "El texto combinado del agente..."
           |
           +----------------------+
                                  |
                                  v
[threadPersistence] -> (Actualiza lastActivity)
           |
           v
[Log: MANUAL_SYNC_SUCCESS]
```

#### Flujo 2: Ciclo de Procesamiento Principal con Function Calling

```ascii
[processCombinedMessage] -> (Adquiere lock, entra a la cola)
           |
           v
[processWithOpenAI] -> (startRequestTracing, getRelevantContext)
           |
           v
[OpenAI API] -> runs.create()
           |
           v
[Polling de Run] -- (status: 'in_progress') --> [Loop]
           |
 (status: 'requires_action')
           |
           v
[Ejecutar Tools] -> executeFunction('check_availability', ...)
           |
           v
[OpenAI API] -> submitToolOutputs()
           |
           v
[Polling Post-Tool] -- (status: 'in_progress') --> [Loop]
           |
  (status: 'completed')
           |
           v
[Obtener Respuesta] -> validateAndCorrectResponse()
           |
           +-- (needsRetry: true) --> [Crear correctiveMessage y re-ejecutar Run]
           |
 (needsRetry: false)
           |
           v
[sendWhatsAppMessage] -> (Enviar respuesta final al usuario)
           |
           v
[endRequestTracing] -> (Guardar mÃ©tricas y logs)
```

::::::::::::::::::::::::::::::::::



# ğŸ“¸ Estado Actual del Sistema

*Snapshot exacto de cÃ³mo funciona el bot ahora, basado en app-unified.ts de 3,779 lÃ­neas al 27 de Julio 2025*

---

## ğŸ” **ARCHIVO PRINCIPAL: app-unified.ts**

### **EstadÃ­sticas:**
- **LÃ­neas**: 3,779
- **Funciones principales**: ~80+ (incluyendo helpers inline y async functions)
- **Imports**: 30+ mÃ³dulos (incluyendo obsoletos comentados para registro)
- **Variables globales**: 25+ (Maps, Sets, constantes y objetos para estado, caches y buffers)
- **Endpoints**: 12+ rutas Express (7 principales + dashboard routes + mÃ©tricas)

### **Estructura Actual (3,779 lÃ­neas):**

```typescript
// IMPORTS (lÃ­neas ~1-150)
import "dotenv/config"; // ConfiguraciÃ³n de entorno
import express, { Request, Response } from 'express'; // Servidor web
import http from 'http'; // CreaciÃ³n de servidor HTTP
import OpenAI from 'openai'; // Cliente OpenAI para Assistant API, TTS, Whisper
import levenshtein from 'fast-levenshtein'; // Distancia de strings (usado en validateAndCorrectResponse)
import path from 'path'; // Manejo de rutas de archivos (temp audio)
import fs from 'fs/promises'; // Operaciones asÃ­ncronas de archivos (audio temporal)

// ConfiguraciÃ³n y utilidades
import { AppConfig, loadAndValidateConfig, logEnvironmentConfig } from './config/environment.js';
import { getConfig } from './config/environment'; // Obsoleto, comentado

// Sistema de logging (~20 funciones)
import {
    logInfo, logSuccess, logError, logWarning, logDebug, logFatal, logAlert,
    // Obsoletos comentados pero importados:
    logMessageReceived, logOpenAIRequest, logOpenAIResponse,
    logFunctionCallingStart, logFunctionExecuting, logFunctionHandler,
    logThreadCreated, logServerStart, logOpenAIUsage, logOpenAILatency,
    logFallbackTriggered, logPerformanceMetrics,
    // Nuevas funciones de tracing:
    logRequestTracing, logToolOutputsSubmitted, logAssistantNoResponse,
    startRequestTracing, updateRequestStage, registerToolCall,
    updateToolCallStatus, endRequestTracing
} from './utils/logging/index.js';

// Persistencia y memoria
import { threadPersistence } from './utils/persistence/index.js';
import { guestMemory } from './utils/persistence/index.js'; // Obsoleto pero importado

// APIs y utilidades externas
import { whapiLabels } from './utils/whapi/index.js';
import type { UserState } from './utils/userStateManager.js';
import { botDashboard } from './utils/monitoring/dashboard.js';
import { validateAndCorrectResponse } from './utils/response-validator.js';

// MÃ©tricas y routing
import metricsRouter, { 
    incrementFallbacks, 
    setTokensUsed, 
    setLatency, 
    incrementMessages 
} from './routes/metrics.js';

// Context y caches
import { cleanupExpiredCaches, getCacheStats } from './utils/context/historyInjection.js';

// Sistema de locks
import { simpleLockManager } from './utils/simpleLockManager.js';

// Function registry (importado dinÃ¡micamente en processWithOpenAI)
// import { executeFunction } from './functions/registry/function-registry.js';

// VARIABLES GLOBALES (lÃ­neas ~150-400)
let appConfig: AppConfig; // ConfiguraciÃ³n cargada (entorno, secrets)
let openaiClient: OpenAI; // Cliente OpenAI inicializado
let server: http.Server; // Servidor HTTP
let isServerInitialized = false; // Flag de inicializaciÃ³n

// Sistema de logs limpios para terminal
const terminalLog = {
    message: (user: string, text: string) => {...}, // Log mensaje usuario
    typing: (user: string) => {...}, // Log typing
    processing: (user: string) => {...}, // Log procesando (eliminado)
    response: (user: string, text: string, duration: number) => {...}, // Log respuesta
    error: (message: string) => {...}, // Error general
    openaiError: (user: string, error: string) => {...}, // Error OpenAI
    imageError: (user: string, error: string) => {...}, // Error imagen
    voiceError: (user: string, error: string) => {...}, // Error voz
    functionError: (functionName: string, error: string) => {...}, // Error funciÃ³n
    whapiError: (operation: string, error: string) => {...}, // Error WHAPI
    functionStart: (name: string, args?: any) => {...}, // Inicio funciÃ³n
    functionProgress: (name: string, step: string, data?: any) => {...}, // Progreso
    functionCompleted: (name: string, result?: any, duration?: number) => {...}, // Completado
    startup: () => {...}, // Log inicio sistema
    newConversation: (user: string) => {...}, // Nueva conversaciÃ³n
    image: (user: string) => {...}, // Imagen recibida
    voice: (user: string) => {...}, // Voz recibida
    recording: (user: string) => {...}, // Grabando
    availabilityResult: (completas: number, splits: number, duration?: number) => {...}, // Resultados Beds24
    externalApi: (service: string, action: string, result?: string) => {...} // APIs externas
};

// Rate limiting y control
const webhookCounts = new Map<string, { lastLog: number; count: number }>(); // Rate limiting logs webhooks
const typingLogTimestamps = new Map<string, number>(); // Rate limiting typing logs (5s)

// Caches con TTL
const chatInfoCache = new Map<string, { data: any; timestamp: number }>(); // Cache info chats
const CHAT_INFO_CACHE_TTL = 5 * 60 * 1000; // 5 minutos
const contextCache = new Map<string, { context: string, timestamp: number }>(); // Cache contexto temporal
const CONTEXT_CACHE_TTL = 60 * 60 * 1000; // 1 hora

// Control de configuraciÃ³n
const SHOW_FUNCTION_LOGS = process.env.TERMINAL_LOGS_FUNCTIONS !== 'false'; // Logs functions en terminal

// Estados y procesamiento
const activeProcessing = new Set<string>(); // Usuarios en procesamiento activo

// Buffer unificado de mensajes
const globalMessageBuffers = new Map<string, {
    messages: string[],
    chatId: string,
    userName: string,
    lastActivity: number,
    timer: NodeJS.Timeout | null,
    currentDelay?: number // Delay actual del timer para comparaciones
}>();
const BUFFER_WINDOW_MS = 5000; // 5 segundos para agrupar mensajes normales
const TYPING_EXTENDED_MS = 10000; // 10 segundos cuando usuario estÃ¡ escribiendo/grabando

// Media y mensajes
const pendingImages = new Map<string, string[]>(); // URLs imÃ¡genes pendientes por usuario
const botSentMessages = new Set<string>(); // IDs de mensajes enviados por bot (evitar self-loops)
const globalUserStates = new Map<string, UserState>(); // Estados de usuario completos

// Control de retries y validaciÃ³n
const userRetryState = new Map<string, { retryCount: number; lastRetryTime: number }>(); // Control retries (evitar loops)

// Constantes
const MAX_MESSAGE_LENGTH = 5000; // LÃ­mite longitud mensajes

// Tipos para WHAPI
interface WHAPIMediaLink {
    link?: string;
    id?: string;
    mime_type?: string;
    file_size?: number;
}

interface WHAPIMessage {
    id: string;
    type: string;
    audio?: WHAPIMediaLink;
    voice?: WHAPIMediaLink;
    ptt?: WHAPIMediaLink;
    image?: WHAPIMediaLink;
}

interface WHAPIError {
    error?: {
        code: number;
        message: string;
        details?: string;
    };
}

// FUNCIONES UTILITARIAS (lÃ­neas ~400-2500)

// Helpers bÃ¡sicos
function getTimestamp(): string {...} // Helper para timestamps ISO
function getShortUserId(jid: string): string {...} // Extrae ID corto de JID
function cleanContactName(rawName: any): string {...} // Limpia nombres de contactos

// GestiÃ³n de estados
function getOrCreateUserState(userId: string, chatId?: string, userName?: string): UserState {...}
async function getCachedChatInfo(userId: string): Promise<any> {...} // Con cache 5min
function invalidateUserCaches(userId: string): void {...} // Invalida caches al cambiar datos

// TranscripciÃ³n y audio
async function transcribeAudio(
    audioUrl: string | undefined, 
    userId: string, 
    userName?: string, 
    messageId?: string
): Promise<string> {...} // Whisper con temp files y cleanup

// Sistema de locks
async function acquireThreadLock(userId: string): Promise<boolean> {...} // Via simpleLockManager
function releaseThreadLock(userId: string): void {...}

// Buffer y procesamiento
function addToGlobalBuffer(
    userId: string, 
    messageText: string, 
    chatId: string, 
    userName: string, 
    isVoice: boolean = false
): void {...} // Agrega con lÃ­mite 50 msgs

function setIntelligentTimer(
    userId: string, 
    chatId: string, 
    userName: string, 
    triggerType: 'message' | 'voice' | 'typing' | 'recording'
): void {...} // Timer dinÃ¡mico 5-10s

async function processGlobalBuffer(userId: string): Promise<void> {...} // Procesa con locks

// Indicadores y detecciÃ³n
async function sendRecordingIndicator(chatId: string): Promise<void> {...} // Presencia "recording"
async function sendTypingIndicator(chatId: string): Promise<void> {...} // Presencia "typing"
function isQuoteOrPriceMessage(message: string): boolean {...} // Detecta sensibles ($/COP/enlaces)

// EnvÃ­o de mensajes
async function sendWhatsAppMessage(chatId: string, message: string): Promise<boolean> {...} 
// Incluye: voice response si lastInputVoice, fallback texto si sensible, divisiÃ³n pÃ¡rrafos

// OpenAI utilities
async function cleanupOldRuns(threadId: string, userId: string): Promise<number> {...} // >10min
async function isRunActive(userId: string): Promise<boolean> {...} // Con cleanup previo
async function recoverOrphanedRuns(): Promise<void> {...} // Al boot, cancela todos

// Cache temporal
let precomputedContextBase: { date: string; time: string; timestamp: number } | null = null;
const CONTEXT_BASE_CACHE_TTL = 60 * 1000; // 1 minuto
function getPrecomputedContextBase(): { date: string; time: string } {...}
async function getRelevantContext(userId: string, requestId?: string): Promise<string> {...}

// Procesamiento principal
let processCombinedMessage: (
    userId: string, 
    combinedText: string, 
    chatId: string, 
    userName: string, 
    messageCount: number
) => Promise<void>; // Definida en setupWebhooks

// SETUP Y CONFIGURACIÃ“N (lÃ­neas ~2500-3000)
function setupEndpoints(): void {...} // Configura todas las rutas Express
function setupSignalHandlers(): void {
    // Manejo de shutdown graceful
    const shutdown = (signal: string) => {
        logInfo('SHUTDOWN', `SeÃ±al ${signal} recibida`);
        
        // 1. Limpiar todos los timers de buffers
        for (const [userId, buffer] of globalMessageBuffers) {
            if (buffer.timer) clearTimeout(buffer.timer);
        }
        
        // 2. Cerrar servidor HTTP
        if (server) {
            server.close(() => {
                logSuccess('SHUTDOWN', 'Servidor cerrado');
                process.exit(0);
            });
        }
        
        // 3. Timeout forzado despuÃ©s de 5s
        setTimeout(() => {
            logWarning('SHUTDOWN', 'Cierre forzado por timeout');
            process.exit(1);
        }, 5000);
    };
    
    process.on('SIGTERM', () => shutdown('SIGTERM'));
    process.on('SIGINT', () => shutdown('SIGINT'));
}
function setupWebhooks(): void {...} // LÃ³gica webhook y processCombinedMessage
function initializeBot(): void {...} // Intervals, cleanups, recovery

// Procesamiento OpenAI principal
async function processWithOpenAI(
    userMsg: string, 
    userJid: string, 
    chatId: string = null, 
    userName: string = null, 
    requestId?: string
): Promise<string> {...} // Thread management, functions, polling, validaciÃ³n

// Procesamiento webhook
async function processWebhook(body: any): Promise<void> {...} // Messages, presences, manuales

// SERVIDOR EXPRESS (lÃ­neas ~3000-3500)
const app = express();
app.use(express.json({ limit: '50mb' }));
app.use('/metrics', metricsRouter); // MÃ©tricas Prometheus (incrementFallbacks, setTokensUsed, setLatency, incrementMessages)

// setupEndpoints() configura:
app.get('/health', (req, res) => {...}); // Health check con stats
app.post('/hook', async (req: Request, res: Response) => {...}); 
// Webhook principal:
// - Responde 200 inmediatamente (evita timeout Whapi)
// - Procesa async en background
// - Filtra webhooks vÃ¡lidos: messages, presences, statuses, chats, contacts, groups, labels, calls, channel, users
// - Rate limiting para webhooks invÃ¡lidos (1 log/min)
app.get('/', (req, res) => {...}); // Root con info bot
app.get('/locks', (req, res) => {...}); // Monitoreo locks
app.post('/locks/clear', (req, res) => {...}); // Limpia locks (solo dev)
app.get('/audio/:filename', async (req, res) => {...}); // Sirve audio temporal
// botDashboard.setupRoutes(app) configura:
// - /dashboard: UI principal
// - /dashboard/logs: Logs en tiempo real
// - /dashboard/stats: EstadÃ­sticas del sistema
// - /dashboard/api/logs: API para logs (WebSocket)

// MANEJADORES GLOBALES (lÃ­neas ~3500-3700)
process.on('uncaughtException', (error, origin) => {...}); // Log crÃ­tico + exit(1)
process.on('unhandledRejection', (reason, promise) => {...}); // Log crÃ­tico + exit(1)

// FUNCIÃ“N PRINCIPAL (lÃ­neas ~3700-3779)
const main = async () => {
    // 1. Logs iniciales (versiÃ³n Node, memoria, entorno)
    // 2. loadAndValidateConfig() â†’ appConfig
    // 3. logEnvironmentConfig()
    // 4. new OpenAI({ apiKey, timeout, maxRetries })
    // 5. setupEndpoints() â†’ todas las rutas
    // 6. setupWebhooks() â†’ lÃ³gica procesamiento
    // 7. http.createServer(app) â†’ server.listen()
    // 8. initializeBot() â†’ cleanups, intervals, recovery
    // 9. setupSignalHandlers() â†’ shutdown graceful
    // 10. Catch: servidor mÃ­nimo si falla (puerto 8080)
};

main();
```

---

## ğŸ”„ **FLUJO DE PROCESAMIENTO ACTUAL**

### **1. RecepciÃ³n de Webhook (processWebhook):**
```
WhatsApp â†’ Whapi â†’ POST /hook â†’ Respuesta 200 inmediata â†’ processWebhook(body) async
                                                    â†“
                                    Validar body (messages/presences/event)
                                                    â†“
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ PRESENCES (typing/recording):                           â”‚
                    â”‚ - Actualizar userState.lastTyping = Date.now()         â”‚
                    â”‚ - setIntelligentTimer(10s extended)                    â”‚
                    â”‚ - terminalLog.typing/recording (rate limited 5s)       â”‚
                    â”‚ - Si status online/offline: limpiar isCurrentlyRecordingâ”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                    â†“
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ MESSAGES:                                               â”‚
                    â”‚ 1. Filtrar from_me:                                     â”‚
                    â”‚    - Si botSentMessages.has(id): skip                  â”‚
                    â”‚    - Si manual real: buffer especial + sync thread     â”‚
                    â”‚ 2. Por tipo:                                           â”‚
                    â”‚    - Voice: transcribeAudio â†’ ğŸ¤ + texto               â”‚
                    â”‚    - Image: pendingImages.set â†’ ğŸ“· Imagen recibida     â”‚
                    â”‚    - Text: ğŸ“ + texto                                  â”‚
                    â”‚ 3. addToGlobalBuffer() con metadata                    â”‚
                    â”‚ 4. setIntelligentTimer (5-10s segÃºn tipo)             â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **2. Procesamiento de Buffer (processGlobalBuffer):**
```
Timer expira (5-10s) â†’ processGlobalBuffer(userId)
                              â†“
        Verificar typing reciente (<10s) y msgs.length === 1
                              â†“ Si sÃ­
                    Retrasar remainingTime (hasta 10s desde lastTyping)
                              â†“ Si no
                    Verificar activeProcessing.has(userId)
                              â†“ Si no
                    Marcar activeProcessing.add(userId)
                              â†“
                    Copiar mensajes y limpiar buffer.messages = []
                              â†“
                    Combinar mensajes con '\n'
                              â†“
                    processCombinedMessage(userId, combinedText, ...)
                              â†“
                    activeProcessing.delete(userId) en finally
```

### **3. LÃ³gica de OpenAI (processCombinedMessage + processWithOpenAI):**
```
processCombinedMessage(userId, combinedText, ...)
                    â†“
        isRunActive() con cleanupOldRuns previo
                    â†“ Si active
        Retry hasta 3 veces (1s delay) o cancelar requires_action
                    â†“
        simpleLockManager.addToQueue(userId, messageId, data, processFunction)
                    â†“
        processFunction():
            â†“
        startRequestTracing(userId) â†’ updateRequestStage('init')
            â†“
        getRelevantContext() si necesario:
            - Condiciones: 3h desde Ãºltimo, cambio nombre/labels, primer mensaje
            - Si cambio detectado â†’ invalidateUserCaches(userId)
            - Genera contexto temporal con fecha/hora/cliente/labels
            â†“
        processWithOpenAI(combinedText, userId, chatId, userName, requestId)
            â”œâ”€ sendTypingIndicator() o sendRecordingIndicator()
            â”œâ”€ Crear/obtener thread (threadPersistence)
            â”œâ”€ Agregar mensaje con contexto temporal
            â”œâ”€ Adjuntar pendingImages si existen
            â”œâ”€ openaiClient.beta.threads.runs.create()
            â”œâ”€ Polling (1s interval, max 30 attempts, backoff en race conditions)
            â”œâ”€ Si completed: obtener respuesta
            â”œâ”€ Si requires_action:
            â”‚   â”œâ”€ Mensaje interino si check_availability complejo
            â”‚   â”œâ”€ executeFunction() para cada tool call
            â”‚   â”‚   â””â”€ registerToolCall() â†’ updateToolCallStatus()
            â”‚   â”œâ”€ submitToolOutputs
            â”‚   â””â”€ Polling post-tool (500ms-5s backoff, max 10)
            â”œâ”€ validateAndCorrectResponse()
            â”‚   â””â”€ Si needsRetry: correctiveMessage + retry run (userRetryState)
            â””â”€ Si context_length_exceeded: crear thread nuevo
                    â†“
        sendWhatsAppMessage(chatId, response)
            â”œâ”€ Si lastInputVoice && !sensible: TTS nova â†’ voice message
            â”œâ”€ Si sensible (precios/enlaces): forzar texto
            â””â”€ DivisiÃ³n inteligente en pÃ¡rrafos con typing_time
                    â†“
        endRequestTracing() + mÃ©tricas (tokens, latency)
```

### **4. Flujos Especiales:**

#### **Mensajes Manuales (from_me: true):**
```
Webhook detecta from_me: true â†’ Verificar NO es botSentMessages.has(id)
    â†“ Si es manual real
Buffer separado en globalMessageBuffers con key=chatId
    â†“
Timer 5s (BUFFER_WINDOW_MS) â†’ Agrupar mÃºltiples mensajes
    â†“
Procesar buffer:
    1. Crear mensaje de contexto:
       await threads.messages.create(threadId, {
         role: 'user',
         content: '[Mensaje manual de {agentName}]'
       })
    2. Agregar contenido real como assistant:
       await threads.messages.create(threadId, {
         role: 'assistant', 
         content: combinedMessage
       })
    â†“
threadPersistence.setThread() actualiza metadata
Log: MANUAL_SYNC_SUCCESS con preview y stats
```

#### **Media Handling:**
```
Voice â†’ transcribeAudio():
    - Verificar audioUrl o fetch desde WHAPI usando messageId
    - Descargar audio con fetch â†’ arrayBuffer
    - Crear temp file: path.join('tmp', `audio_${Date.now()}.ogg`)
    - fs.writeFile(tempPath, Buffer.from(audioBuffer))
    - createReadStream para OpenAI Whisper
    - OpenAI transcription con model='whisper-1', language='es'
    - fs.unlink(tempPath).catch(() => {}) // Ignorar error si falla
    - Retornar transcripciÃ³n o 'No se pudo transcribir el audio'
    - Si error: terminalLog.voiceError(displayName, error.message)

Image â†’ pendingImages:
    - Extraer URL de message.image?.link
    - Si no hay URL, fetch desde WHAPI similar a voice
    - pendingImages.get(userId).push(imageUrl)
    - Al procesar con OpenAI:
      content: [
        { type: "text", text: messageWithContext },
        { type: "image_url", image_url: { url: imageUrl }}
      ]
    - Limpiar pendingImages.delete(userId) post-uso
```

#### **Voice Responses con Fallback Inteligente:**
```
Si lastInputVoice === true && ENABLE_VOICE_RESPONSES === 'true':
    â†“
Verificar contenido sensible con isQuoteOrPriceMessage():
    - Regex patterns:
      /\$\d+[.,]?\d*/g              // $840.000
      /\d+[.,]?\d*\s*(cop|pesos?)/gi // 840000 COP
      /\d+\s*noches?/gi             // 4 noches
      /https?:\/\/\S+/i             // URLs
      /wa\.me\/p/i                  // Enlaces WhatsApp
    â†“ Si match â†’ Forzar texto (shouldUseVoice = false)
    
Si shouldUseVoice:
    - OpenAI TTS: model='tts-1', voice='nova', max 4000 chars
    - Convertir response a arrayBuffer â†’ Buffer â†’ base64
    - Crear data URL: `data:audio/mp3;base64,${base64Audio}`
    - POST a Whapi /messages/voice con media: dataUrl
    - Si OK: limpiar userState.lastInputVoice = false
    - Si error: fallback a texto normal
    
EnvÃ­o de texto (normal o fallback):
    - DivisiÃ³n inteligente por pÃ¡rrafos (\n\n+)
    - O por listas con bullets (â€¢, -, *)
    - typing_time: 3s primer msg, 2s siguientes
    - Guardar en botSentMessages.add(responseId)
    - Auto-delete despuÃ©s de 10 min
```

### **5. Cleanup y Recovery:**

```
AL BOOT:
    - threadPersistence.initializeCleanup()
    - recoverOrphanedRuns() en background (5s delay)
        â””â”€ Cancelar TODOS los runs activos

INTERVALS:
    - cleanupExpiredCaches() cada 10 min
    - Memory logs cada 5 min (alert si >300MB o >95% heap)
    - User states cleanup cada 1h (>24h inactivo)
    - Global buffer cleanup cada 10 min (>15 min inactivo)
    
SHUTDOWN (SIGTERM/SIGINT):
    - Clear todos los timers
    - server.close() con timeout 5s
    - Logs de shutdown detallados
```

### **6. Sistema de Tracing:**
```
startRequestTracing(userId) â†’ requestId
    â†“
updateRequestStage(requestId, 'init'|'processing'|'function_calling'|'completed')
    â†“
registerToolCall(requestId, toolCallId, functionName, 'executing')
    â†“
updateToolCallStatus(requestId, toolCallId, 'success'|'error')
    â†“
endRequestTracing(requestId) â†’ summary con duraciÃ³n total
```

---

## ğŸ—„ï¸ **DATOS QUE MANEJA**

### **En Memoria (VolÃ¡til con TTLs):**

```typescript
// BUFFERS Y ESTADOS
globalMessageBuffers: Map<string, {
    messages: string[],        // Hasta 50 msgs
    chatId: string,
    userName: string,
    lastActivity: number,      // Para cleanup >15min
    timer: NodeJS.Timeout | null,
    currentDelay?: number      // 5000ms normal, 10000ms si typing/recording activo
}>

globalUserStates: Map<string, UserState> {
    userId: string,
    isTyping: boolean,
    lastTypingTimestamp: number,
    lastMessageTimestamp: number,
    messages: string[],
    chatId: string,
    userName: string,
    typingEventsCount: number,
    averageTypingDuration: number,
    lastInputVoice: boolean,   // Para voice responses
    lastTyping: number,        // Ãšltimo typing detectado
    isCurrentlyRecording?: boolean
}

// CACHES CON TTL
contextCache: Map<string, {    // TTL: 1 hora
    context: string,           // Contexto temporal formateado
    timestamp: number
}>

chatInfoCache: Map<string, {   // TTL: 5 minutos
    data: any,                 // Info de Whapi (name, labels)
    timestamp: number
}>

// CONTROL Y RATE LIMITING
activeProcessing: Set<string>  // Durante procesamiento

botSentMessages: Set<string>   // TTL: 10 minutos auto-delete
                              // IDs para evitar self-loops

userRetryState: Map<string, {  // Control retries validaciÃ³n
    retryCount: number,        // Max 1 retry
    lastRetryTime: number      // Cooldown 5 minutos
}>

pendingImages: Map<string, string[]>  // URLs por usuario
// Se adjuntan a OpenAI como content multimodal:
// [{ type: "text", text: msg }, { type: "image_url", image_url: { url } }]

webhookCounts: Map<string, {   // Rate limiting logs
    lastLog: number,
    count: number
}>

typingLogTimestamps: Map<string, number>  // Rate limit 5s

// CACHE TEMPORAL
precomputedContextBase: {      // TTL: 1 minuto
    date: string,
    time: string,
    timestamp: number
} | null
```

### **En Archivos JSON (Persistente):**

```json
// threads-data.json (via threadPersistence)
{
  "573001234567": {
    "threadId": "thread_abc123",
    "chatId": "573001234567@s.whatsapp.net",
    "userName": "Juan PÃ©rez",
    "createdAt": "2025-07-27T10:30:00Z",
    "lastActivity": "2025-07-27T15:45:00Z",
    "name": "Juan PÃ©rez",         // Para detectar cambios
    "labels": ["Consulta", "VIP"]  // Para detectar cambios
  }
}

// guest-memory.json (obsoleto pero aÃºn importado)
{
  "573001234567": {
    "name": "Juan PÃ©rez",
    "whapiLabels": [
      {"id": "1", "name": "Potencial"},
      {"id": "2", "name": "Consulta"}
    ],
    "lastInteraction": "2025-07-27T15:45:00Z"
  }
}
```

### **Archivos Temporales:**
```
/tmp/
â”œâ”€â”€ audio_1234567890.ogg    // TranscripciÃ³n Whisper (deleted post-uso)
â”œâ”€â”€ audio_1234567891.mp3    // TTS output (deleted post-envÃ­o)
â””â”€â”€ ...

âš ï¸ Riesgo: Si fs.unlink() falla, archivos se acumulan
MitigaciÃ³n actual: .catch(() => {}) ignora errores
Problema: No hay cleanup periÃ³dico de /tmp/
```

---

## ğŸ¨ **FUNCIONALIDADES ESPECÃFICAS DE HOTELERÃA**

### **Check Availability Function:**
```typescript
// Registrada en function-registry.js
{
    name: "check_availability",
    description: "Verificar disponibilidad y precios en el sistema",
    parameters: {
        type: "object",
        properties: {
            startDate: { type: "string", description: "YYYY-MM-DD" },
            endDate: { type: "string", description: "YYYY-MM-DD" },
            guests: { type: "number", default: 2 }
        }
    }
}

// EjecuciÃ³n:
executeFunction("check_availability", args) â†’
    - Calcular noches
    - Llamar Beds24 API (JSON endpoint)
    - Parsear respuesta XML
    - Aplicar timezone America/Bogota
    - Formatear: completas (disponibles) + splits (alternativas)
    - terminalLog.availabilityResult(completas, splits, duration)
```

### **Labels Hoteleros:**
```typescript
// Via whapiLabels y getCachedChatInfo
Etiquetas disponibles: [
    'Potencial',      // Cliente interesado
    'Consulta',       // En proceso de cotizaciÃ³n
    'Reservado',      // ConfirmÃ³ reserva
    'VIP',           // Cliente especial
    'Check-in',      // En hotel
    'Check-out',     // SaliÃ³ del hotel
    'Cancelado',     // CancelÃ³ reserva
    'Repetidor'      // Cliente recurrente
]
```

### **Contexto Temporal:**
```typescript
// Inyectado automÃ¡ticamente cada 3h o al cambiar datos
`Fecha: 27/07/2025 | Hora: 10:30 AM (Colombia)
Cliente: Juan PÃ©rez | Contacto WhatsApp: Juan | Status: Consulta, VIP
---
Mensaje del cliente:`
```

### **ValidaciÃ³n y CorrecciÃ³n:**
- **DetecciÃ³n sensible**: Regex para $, COP, precios, URLs (fallback voiceâ†’text)
- **ValidaciÃ³n respuestas**: levenshtein distance para discrepancias
- **CorrecciÃ³n**: Manual o retry automÃ¡tico con correctiveMessage
- **Timezone**: Todas las fechas/horas en America/Bogota

---

## âš¡ **PERFORMANCE ACTUAL**

### **MÃ©tricas TÃ­picas:**
- **Tiempo respuesta promedio**: 3-8s (OpenAI 1-5s + Beds24 2-5s)
- **Memoria RAM**: 150-400MB (alertas >300MB, crÃ­tico >95% heap)
- **CPU**: 10-40% en picos (TTS/Whisper intensive)
- **Usuarios concurrentes**: 50-200 tÃ­pico, mÃ¡x 500
- **Requests/min**: 200-1000 (webhooks + API calls)
- **Tokens/request**: 500-3000 (alertas >2000)

### **Bottlenecks Identificados:**
1. **OpenAI Polling**: 1-3s base + backoff (puede llegar a 30s timeout)
2. **Beds24 API**: 2-5s tÃ­pico, ~20% timeouts
3. **Transcripciones Audio**: 3-10s (descarga + Whisper + temp file)
4. **TTS Generation**: 2-5s para respuestas largas
5. **Memory Growth**: Caches sin lÃ­mite estricto (mitigado con intervals)

### **Memory Leaks Potenciales:**
- **globalMessageBuffers**: Timers no cancelados en race conditions
- **contextCache/chatInfoCache**: Crecimiento sin lÃ­mite mÃ¡ximo
- **globalUserStates**: Cleanup cada hora pero puede acumular
- **pendingImages**: No tiene TTL explÃ­cito
- **Temp files**: Si fs.unlink falla, acumulaciÃ³n en /tmp

---

## ğŸ”Œ **INTEGRACIONES EXTERNAS**

### **OpenAI Assistant API:**
```yaml
Endpoint: https://api.openai.com/v1
Assistant ID: process.env.OPENAI_ASSISTANT_ID
Models:
  - whisper-1: TranscripciÃ³n audio (espaÃ±ol)
  - tts-1: Text-to-speech (voice: nova)
  - gpt-4: Assistant principal
Functions disponibles:
  - check_availability
  - get_conversation_context
  - view_image
  - search_knowledge
Rate limits: 
  - Timeout: configurable en appConfig
  - Retries: configurable en appConfig
Manejo errores:
  - context_length_exceeded â†’ Nuevo thread automÃ¡tico
  - Runs huÃ©rfanos â†’ Cleanup automÃ¡tico
  - Race conditions â†’ Backoff progresivo
```

### **Whapi Cloud:**
```yaml
Endpoint: ${WHAPI_API_URL} (e.g., https://gate.whapi.cloud/)
Token: ${WHAPI_TOKEN}
Endpoints usados:
  - /messages/text: Enviar mensajes texto
  - /messages/voice: Enviar notas de voz
  - /presences/{id}: Suscribir/actualizar presencia
  - /messages/{id}: Obtener info mensaje (media URLs)
  - /chats/{id}: Obtener info chat
Funcionalidades:
  - Labels management
  - Presences (typing, recording, online)
  - Media handling (images, voice)
Rate limits: No documentado
Webhooks: POST /hook
```

### **Beds24 API:**
```yaml
Endpoint: https://beds24.com/api/json/
Auth: 
  - apiKey: En secrets
  - propKey: En secrets
Endpoints:
  - getAvailabilities: Disponibilidad y precios
Response: XML (parseado a JSON)
Timezone: UTC â†’ America/Bogota
Rate limits: No documentado
Timeouts: ~20% de requests
Formato respuesta:
  - roomId, units available
  - prices por noche
  - min stay requirements
```

---

## ğŸ› ï¸ **SISTEMAS AUXILIARES**

### **Sistema de Logging (terminalLog):**
```typescript
// Objeto con ~20 mÃ©todos para logs limpios
terminalLog = {
    // Mensajes bÃ¡sicos
    message(user, text): "ğŸ‘¤ user: text..."
    typing(user): "âœï¸ user estÃ¡ escribiendo..."
    response(user, text, duration): "ğŸ¤– OpenAI â†’ user (Xs)"
    
    // Errores especÃ­ficos
    error(message): "âŒ Error: message"
    openaiError(user, error): "âŒ Error enviar a OpenAI â†’ user"
    imageError(user, error): "âŒ Error al procesar imagen â†’ user"
    voiceError(user, error): "âŒ Error al procesar audio â†’ user"
    functionError(name, error): "âŒ Error en funciÃ³n name"
    whapiError(operation, error): "âŒ Error WHAPI (operation)"
    
    // Function calling
    functionStart(name, args): "âš™ï¸ name(args)"
    functionCompleted(name, result, duration): Log segÃºn funciÃ³n
    availabilityResult(completas, splits, duration): "ğŸ  X completas + Y alternativas (Xs)"
    
    // Sistema
    startup(): Clear + banner inicial
    newConversation(user): "ğŸ“¨ Nueva conversaciÃ³n con user"
    image(user): "ğŸ“· user: [Imagen recibida]"
    voice(user): "ğŸ¤ user: [Nota de voz recibida]"
    recording(user): "ğŸ™ï¸ user estÃ¡ grabando..."
    externalApi(service, action, result): "ğŸ”— [timestamp] service â†’ action"
}
```

### **Sistema de Locks (simpleLockManager):**
```typescript
// Sistema hÃ­brido con locks y colas por usuario
ConfiguraciÃ³n:
    - Tipo: user-based (un lock por userId)
    - Timeout: 15 segundos (auto-release si no se libera)
    - Queue: habilitada (procesa en orden FIFO)
    - Auto-release: sÃ­ (previene deadlocks)
    - Concurrencia: 1 proceso por usuario a la vez
    
MÃ©todos principales:
    - acquireUserLock(userId): Promise<boolean>
      â””â”€ Intenta adquirir lock, retorna true si Ã©xito
    - releaseUserLock(userId): void
      â””â”€ Libera lock y procesa siguiente en cola
    - addToQueue(userId, messageId, data, processFunction): void
      â””â”€ Agrega a cola si lock ocupado
    - processQueue(userId): Promise<void>
      â””â”€ Procesa items en cola secuencialmente
    - hasActiveLock(userId): boolean
      â””â”€ Verifica si usuario tiene lock activo
    - getStats(): {activeLocks: number, activeQueues: number}
      â””â”€ EstadÃ­sticas del sistema
    - clearAll(): void
      â””â”€ Limpia todos los locks (solo desarrollo)

Uso en el flujo:
    1. processCombinedMessage intenta acquireThreadLock
    2. Si ocupado â†’ addToQueue con processFunction
    3. Al terminar â†’ releaseThreadLock
    4. Auto-procesa siguiente en cola
```

### **Sistema de Tracing:**
```typescript
// Request lifecycle tracking
Funciones:
    - startRequestTracing(userId): string (requestId)
    - updateRequestStage(requestId, stage): void
    - registerToolCall(requestId, toolCallId, name, status): void
    - updateToolCallStatus(requestId, toolCallId, status): void
    - endRequestTracing(requestId): TracingSummary
    
Stages: init â†’ processing â†’ function_calling â†’ post_tools_completed â†’ completed
Tool status: executing â†’ success|error
```

---

## ğŸš¨ **PROBLEMAS CONOCIDOS**

### **CrÃ­ticos:**
1. **Memory leaks sin mitigaciÃ³n completa**
   - Caches crecen indefinidamente si cleanup intervals fallan
   - Causa crashes en Cloud Run tras ~24h de uptime
   - contextCache/chatInfoCache sin lÃ­mite mÃ¡ximo de entradas
   - globalUserStates puede acumular miles de usuarios
   - MitigaciÃ³n actual: Restart diario manual

2. **Persistencia no escalable**
   - JSON files para threads (I/O blocking)
   - PÃ©rdida de memoria/estados al reiniciar
   - No soporta mÃºltiples instancias

3. **CÃ³digo monolÃ­tico inmantenible**
   - 3,779 lÃ­neas en un archivo
   - Funciones dispersas sin organizaciÃ³n clara
   - Imports obsoletos comentados por todas partes

4. **Runs huÃ©rfanos facturaciÃ³n extra**
   - Si cleanup falla, runs activos indefinidos
   - Costo adicional OpenAI (~$0.03/run abandonado)

### **Altos:**
1. **Beds24 API inestable**
   - ~20% timeouts sin retry automÃ¡tico
   - Afecta UX en cotizaciones
   - Sin circuit breaker

2. **Voice handling frÃ¡gil**
   - Transcripciones fallan si no hay URL
   - TTS limitado a 4000 caracteres
   - Temp files pueden acumular si cleanup falla

3. **ValidaciÃ³n puede causar loops**
   - userRetryState mitiga pero no elimina
   - Errores complejos no siempre corregibles
   - Puede agotar tokens rÃ¡pidamente

4. **Webhook processing sin deduplicaciÃ³n**
   - Mensajes duplicados procesados mÃºltiples veces
   - Rate limiting solo en logs, no en procesamiento

### **Medios:**
1. **Sin tests automatizados**
   - Cambios rompen flujos sin detecciÃ³n
   - Regresiones frecuentes en buffers/timers

2. **Logs excesivamente verbosos**
   - ~100 logs por request en modo debug
   - Dificulta debugging real en producciÃ³n

3. **MÃ©tricas incompletas**
   - No tracking de memory leaks especÃ­ficos
   - No histogramas de latencia
   - No alertas automÃ¡ticas configuradas

4. **ConfiguraciÃ³n mezclada local/cloud**
   - Riesgo de usar config incorrecta
   - Secrets en .env no rotados

5. **Dashboard bÃ¡sico**
   - Solo logs en tiempo real
   - No histÃ³ricos ni analytics
   - No filtros avanzados

---

## ğŸ“Š **MÃ‰TRICAS Y MONITOREO**

### **Endpoints de Monitoreo:**
- `/health`: Status general + thread stats
- `/metrics`: MÃ©tricas Prometheus (fallbacks, tokens, latency)
- `/locks`: Estado del sistema de locks
- `/dashboard`: UI web con logs en tiempo real
- `/`: Info general del bot

### **MÃ©tricas Trackeadas:**
- Messages procesados (incrementMessages)
- Fallbacks OpenAI (incrementFallbacks)
- Tokens usados (setTokensUsed)
- Latencia requests (setLatency)
- Memory usage (cada 5min)
- Active threads/buffers

---

*Documento generado el 27 de Julio 2025 - VersiÃ³n 1.0.0-unified-secure*

## ğŸ“ **NOTA IMPORTANTE PARA MIGRACIÃ“N**

Este documento es crÃ­tico para la migraciÃ³n modular. Cualquier funcionalidad no documentada aquÃ­ corre el riesgo de perderse durante la refactorizaciÃ³n. Verificar contra el cÃ³digo fuente completo antes de iniciar la migraciÃ³n.

### **Checklist Pre-MigraciÃ³n:**
- [ ] Verificar que todos los Maps/Sets tengan estrategia de migraciÃ³n
- [ ] Confirmar que todos los timers se manejen correctamente en mÃ³dulos
- [ ] Asegurar que userRetryState y botSentMessages se migren para evitar loops
- [ ] Validar que el cleanup de temp files funcione en nueva arquitectura
- [ ] Probar que invalidateUserCaches funcione entre mÃ³dulos
- [ ] Verificar que el sistema de locks mantenga su integridad

AGREGAR:

(SecciÃ³n Nueva para Agregar al Documento, despuÃ©s de "ğŸ” ARCHIVO PRINCIPAL")
ğŸ“¦ Dependencias Principales (de package.json)
express: ^4.18.2
openai: ^4.0.0 (Assistant API v2 beta)
fast-levenshtein: ^2.0.6
fs/promises: Node built-in (v20+)
dotenv: ^16.0.0
... (lista completa; usar npm list --depth=0 para generar).
Dev: vitest/jest para testing (sugerido, no implementado).
Vulnerabilities: Ejecutar npm audit regularmente; actual ~5 low-severity en deps como express.
(SecciÃ³n Nueva para Agregar al Documento, despuÃ©s de "âš¡ PERFORMANCE ACTUAL")
ğŸš€ Despliegue e Infraestructura
Entornos: Local (node app-unified.ts) + Cloud Run (Dockerized, auto-scale 0-100 instancias).
Config: Env vars via Cloud Secrets; limits: 1CPU/512MB RAM (noted memory leaks >300MB causan crashes).
CI/CD: Manual (git push); sugerido: GitHub Actions con tests + deploy.
Healthchecks: /health endpoint (200 OK con stats); Cloud Run usa para readiness.
Logs: Console + Cloud Logging; no structured export.
(ExpansiÃ³n de la SecciÃ³n Existente "ğŸ§ª Estrategia de Testing")
Ejemplos de Tests (Vitest/Jest):

Unit: test('getShortUserId', () => { expect(getShortUserId('123@s.whatsapp.net')).toBe('123'); });
Integration: test('transcribeAudio', async () => { mockOpenAI(); expect(await transcribeAudio('url')).toContain('transcripciÃ³n'); });
Cobertura Actual: 0% (sin tests); Meta: 80% en migraciÃ³n.
(AdiciÃ³n a "ğŸ¨ FUNCIONALIDADES ESPECÃFICAS DE HOTELERÃA")
UX Flows: Agente manual: EnvÃ­a msg â†’ Sync en 5s â†’ OpenAI actualizado. Usuario: Voz â†’ Transcribe â†’ Responde voz (si no sensible).
Analytics: No implementado; sugerido: Track bookings via Beds24 + GA4 para conversiones.