# 6. Procesamiento Principal y Flujos de OpenAI con Webhooks

> **Introducci√≥n**: Esta secci√≥n detalla el n√∫cleo operativo del bot. Cubre desde la recepci√≥n inicial de un webhook hasta la entrega de una respuesta final al usuario. Se explican los flujos de agrupaci√≥n de mensajes, el manejo de concurrencia mediante locks, la orquestaci√≥n de la l√≥gica con la API de OpenAI (incluyendo `function calling` y manejo de media), y los flujos especiales para garantizar una interacci√≥n robusta y coherente.

## Ubicaci√≥n en el C√≥digo
* **Recepci√≥n y L√≥gica de Webhooks**: `setupEndpoints()` y `processWebhook()` (l√≠neas `~3000-3500` y `~2000-2500`).
* **L√≥gica de Buffering y Timers**: `addToGlobalBuffer()`, `setIntelligentTimer()`, `processGlobalBuffer()` (definidas en la secci√≥n de utilidades, `~1000-1200`).
* **N√∫cleo de OpenAI**: `processCombinedMessage` y `processWithOpenAI()` (anidadas dentro de `setupWebhooks`, `~2500-3000`).
* **Manejo de Media**: `transcribeAudio()` y `analyzeImage()` (secci√≥n de utilidades, `~600-900`).

## 1. Recepci√≥n y Procesamiento Inicial del Webhook

El flujo comienza cuando Whapi Cloud env√≠a una petici√≥n `POST` al endpoint `/hook`.

### Endpoint `/hook`
* **Respuesta Inmediata**: El servidor responde con un `status 200` de forma inmediata. Esto es cr√≠tico para evitar que Whapi considere la entrega como fallida por timeout. El procesamiento real ocurre de forma as√≠ncrona.

```typescript
app.post('/hook', async (req: Request, res: Response) => {
    res.status(200).json({ received: true, timestamp: new Date().toISOString() });
    
    // Procesamiento as√≠ncrono sin bloquear respuesta
    setImmediate(() => {
        processWebhook(req.body).catch(error => {
            terminalLog.error(`Webhook processing failed: ${error.message}`);
        });
    });
});
```

### Funci√≥n `processWebhook`
Esta funci√≥n es el controlador principal que discrimina el tipo de evento recibido:

#### Eventos de Presencia (`presences`)
* Si un usuario est√° `typing` o `recording`, se actualiza su estado en `globalUserStates`
* Se llama a `setIntelligentTimer` con un delay extendido de **10 segundos** para darle tiempo a terminar de escribir o grabar
* Los logs en la terminal (`‚úçÔ∏è...`, `üéôÔ∏è...`) est√°n limitados a uno cada 5 segundos para no saturar la consola
* Se limpia `isCurrentlyRecording` cuando el usuario va `online` o `offline`

#### Eventos de Mensajes (`messages`)
Se itera sobre cada mensaje para dirigirlo al flujo correspondiente seg√∫n su tipo.

### Tabla de Manejo por Tipo de Mensaje
| Tipo | L√≥gica de Procesamiento | Funciones Clave | Notas Adicionales |
|------|--------------------------|------------------|-------------------|
| **Texto** | El mensaje se agrega al `globalMessageBuffers` precedido por "üìù". | `addToGlobalBuffer` | Se establece `lastInputVoice = false` en el `UserState`. |
| **Voz/Audio** | Si `ENABLE_VOICE_TRANSCRIPTION` es `true`, el audio se transcribe usando `transcribeAudio`. El texto resultante se agrega al buffer como "üé§ [transcripci√≥n]". | `transcribeAudio` | Establece `lastInputVoice = true` para permitir respuestas de voz. Utiliza un archivo temporal en `/tmp/` que se elimina post-procesamiento. |
| **Imagen** | Se invoca `analyzeImage` para obtener una descripci√≥n contextual usando `gpt-4o-mini`. La URL original de la imagen se almacena en `pendingImages` para ser usada como contenido multimodal. | `analyzeImage`, `pendingImages.push` | La descripci√≥n de la imagen y un placeholder "üì∑" se agregan al buffer. |
| **Manual (`from_me`)** | Si el mensaje no proviene del bot (no est√° en `botSentMessages`), se trata como una intervenci√≥n de un agente. Se agrupa en un buffer especial (usando el `chatId` como clave) y, tras 5 segundos, se sincroniza con el thread de OpenAI. | `threads.messages.create` (roles `user` y `assistant`) | Es vital para que la IA sepa lo que los agentes humanos han comunicado. |

## 2. Agrupaci√≥n Inteligente y Procesamiento de Buffers

Para que la conversaci√≥n sea natural y no interrumpir al usuario, los mensajes se agrupan antes de ser procesados.

### Sistema de Buffering
* **`globalMessageBuffers`**: Un `Map` que almacena los mensajes entrantes por `userId`
* **L√≠mite de Buffer**: M√°ximo 50 mensajes por usuario para evitar memory leaks
* **Flujo de Datos**: `Webhook` ‚Üí `processWebhook` ‚Üí `addToGlobalBuffer` ‚Üí `setIntelligentTimer` ‚Üí (expira) ‚Üí `processGlobalBuffer`

### `setIntelligentTimer` - Gesti√≥n de Tiempo de Espera
Esta funci√≥n gestiona el tiempo de espera inteligente basado en el tipo de actividad:

* **5 segundos** para mensajes de texto e im√°genes (`BUFFER_WINDOW_MS`)
* **8-10 segundos** para mensajes de voz (m√°s tiempo de procesamiento)
* **10 segundos** si el usuario est√° escribiendo o grabando (`TYPING_EXTENDED_MS`)

**L√≥gica de Timer**:
```typescript
function setIntelligentTimer(userId: string, chatId: string, userName: string, triggerType: 'message' | 'voice' | 'typing' | 'recording'): void {
    const delays = {
        'message': 5000,
        'voice': 8000,
        'typing': 10000,
        'recording': 10000
    };
    
    const newDelay = delays[triggerType];
    const buffer = globalMessageBuffers.get(userId);
    
    // Solo establece/extiende si el nuevo delay es mayor al actual
    if (!buffer?.timer || newDelay > buffer.currentDelay) {
        if (buffer?.timer) clearTimeout(buffer.timer);
        
        buffer.timer = setTimeout(() => processGlobalBuffer(userId), newDelay);
        buffer.currentDelay = newDelay;
    }
}
```

### `processGlobalBuffer` - Consolidaci√≥n de Mensajes
Cuando el timer expira, esta funci√≥n:

1. **Verifica typing reciente**: Si hay solo 1 mensaje y el usuario escribi√≥ hace <10s, retrasa el procesamiento
2. **Previene concurrencia**: Usa `activeProcessing` Map para evitar procesamiento simult√°neo
3. **Consolida mensajes**: Combina todos los mensajes del buffer en un solo texto (separados por `\n`)
4. **Pasa control**: Llama a `processCombinedMessage` con el mensaje consolidado

## 3. Gesti√≥n de Concurrencia con Locks y Colas

Para evitar procesar m√∫ltiples mensajes de un mismo usuario simult√°neamente (race conditions), se utiliza un sistema de locks y colas.

### `processCombinedMessage` - Puerta de Entrada al Lock Manager
Esta funci√≥n act√∫a como intermediario cr√≠tico:

**Responsabilidades principales**:
1. **Verificaci√≥n de Run Activo**: Usa `isRunActive()` con `cleanupOldRuns()` para verificar si hay un run de OpenAI en progreso
2. **Retry Logic**: Si hay un run activo, reintenta hasta 3 veces con delay de 1 segundo, cancelando runs en `requires_action` si es necesario
3. **Encolado**: En lugar de ejecutar la l√≥gica de OpenAI directamente, encola la tarea usando `simpleLockManager.addToQueue`

```typescript
async function processCombinedMessage(userMsg: string, userJid: string, chatId: string, userName: string): Promise<void> {
    // 1. Verificar y limpiar runs activos
    if (isRunActive) {
        for (let i = 0; i < 3; i++) {
            await new Promise(resolve => setTimeout(resolve, 1000));
            const run = await openaiClient.beta.threads.runs.retrieve(threadId, runId);
            if (run.status === 'requires_action') {
                await cancelRun(threadId, runId);
                break;
            }
            if (run.status !== 'in_progress') break;
        }
    }
    
    // 2. Encolar para procesamiento secuencial
    await simpleLockManager.addToQueue(userJid, async () => {
        await processFunction(userMsg, userJid, chatId, userName);
    });
}
```

### `simpleLockManager` - Garant√≠a de Procesamiento Secuencial
* **FIFO Queue**: Procesa las tareas en orden de llegada por usuario
* **Un Lock por Usuario**: Permite concurrencia entre diferentes usuarios pero serializa para cada usuario individual
* **Prevenci√≥n de Race Conditions**: Evita que m√∫ltiples requests del mismo usuario interfieran entre s√≠

## 4. Orquestaci√≥n Principal con OpenAI (`processWithOpenAI`)

Esta es la funci√≥n m√°s compleja, donde ocurre la interacci√≥n con la API de OpenAI. Se ejecuta secuencialmente gracias al `simpleLockManager`.

### Flujo de Procesamiento Paso a Paso

#### 1. Inicio y Tracing
```typescript
const traceId = startRequestTracing(userJid, chatId);
updateRequestStage(traceId, 'init');
```

#### 2. Contexto Temporal con `getRelevantContext`
Se determina si es necesario inyectar contexto. Las condiciones son:
* Han pasado m√°s de **3 horas** desde la √∫ltima interacci√≥n
* El nombre del contacto o sus etiquetas han cambiado
* Es el primer mensaje de la conversaci√≥n

**Cuando se detecta cambio**:
```typescript
if (needsContext) {
    invalidateUserCaches(userJid); // Fuerza recarga de datos
    const contextualMessage = await getRelevantContext(userMsg, userJid, chatId);
    // Usa getPrecomputedContextBase cache TTL 1min para fecha/hora
}
```

#### 3. Gesti√≥n de Threads y Presencias
```typescript
// Obtener o crear thread
const threadId = await getOrCreateThread(userJid);

// Suscribirse a presencias (solo si no est√° ya suscrito)
if (!subscribedPresences.has(userJid)) {
    await subscribeToPresence(userJid);
    subscribedPresences.add(userJid);
}

// Limpiar runs antiguos si es thread nuevo
if (isNewThread) {
    await cleanupOldRuns(threadId);
}
```

#### 4. Creaci√≥n de Mensaje Multimodal
El mensaje del usuario, el contexto temporal y las URLs de im√°genes pendientes se combinan:

```typescript
const messageContent = [];

// Texto principal
messageContent.push({
    type: 'text',
    text: contextualMessage || userMsg
});

// Im√°genes pendientes (multimodal)
if (pendingImages.length > 0) {
    pendingImages.forEach(imageUrl => {
        messageContent.push({
            type: 'image_url',
            image_url: { url: imageUrl, detail: 'low' }
        });
    });
    pendingImages.length = 0; // Limpiar despu√©s de usar
}

await openaiClient.beta.threads.messages.create(threadId, {
    role: 'user',
    content: messageContent
});
```

#### 5. Creaci√≥n y Polling del Run
```typescript
const run = await openaiClient.beta.threads.runs.create(threadId, {
    assistant_id: ASSISTANT_ID
});

// Polling con manejo de race conditions
let attempts = 0;
while (attempts < 30) {
    try {
        const currentRun = await openaiClient.beta.threads.runs.retrieve(threadId, run.id);
        
        if (currentRun.status === 'completed') {
            // Procesar respuesta final
            break;
        } else if (currentRun.status === 'requires_action') {
            // Manejar function calling
            await handleRequiresAction(threadId, run.id, currentRun);
            break;
        }
        
        await new Promise(resolve => setTimeout(resolve, 1000));
        attempts++;
    } catch (error) {
        // Backoff exponencial en race conditions
        const delay = Math.min((attempts + 1) * 1000, 5000);
        await new Promise(resolve => setTimeout(resolve, delay));
    }
}
```

#### 6. Manejo de `requires_action` (Function Calling)
Cuando el run requiere ejecutar funciones, la l√≥gica se maneja **inline**:

```typescript
if (run.status === 'requires_action') {
    const toolOutputs = [];
    
    for (const toolCall of run.required_action.submit_tool_outputs.tool_calls) {
        // Importaci√≥n din√°mica del registry
        const { executeFunction } = await import('./functions/registry/function-registry.js');
        
        // Tracing de la llamada
        registerToolCall(toolCall.function.name, toolCall.id);
        updateToolCallStatus(toolCall.id, 'executing');
        
        // Log visual en terminal
        terminalLog.functionStart(`‚öôÔ∏è ${toolCall.function.name}(${JSON.stringify(JSON.parse(toolCall.function.arguments))})`);
        
        try {
            const result = await executeFunction(toolCall.function.name, JSON.parse(toolCall.function.arguments));
            updateToolCallStatus(toolCall.id, 'success');
            
            toolOutputs.push({
                tool_call_id: toolCall.id,
                output: JSON.stringify(result)
            });
            
            terminalLog.functionSuccess(`‚úÖ ${toolCall.function.name} completed`);
        } catch (error) {
            updateToolCallStatus(toolCall.id, 'error');
            toolOutputs.push({
                tool_call_id: toolCall.id,
                output: JSON.stringify({ error: error.message })
            });
            
            terminalLog.functionError(`‚ùå ${toolCall.function.name} failed: ${error.message}`);
        }
    }
    
    // Enviar resultados y continuar polling
    await openaiClient.beta.threads.runs.submitToolOutputs(threadId, run.id, {
        tool_outputs: toolOutputs
    });
    
    // Polling post-tool con backoff (m√°x. 10 intentos)
    await pollPostToolExecution(threadId, run.id);
}
```

#### 7. Procesamiento de Respuesta Final
```typescript
if (run.status === 'completed') {
    const messages = await openaiClient.beta.threads.messages.list(threadId, { limit: 1 });
    const response = messages.data[0].content[0].text.value;
    
    // Validaci√≥n y correcci√≥n
    const { correctedResponse, needsRetry } = await validateAndCorrectResponse(response, toolOutputs);
    
    if (needsRetry && canRetry(userJid)) {
        // Retry con correctiveMessage
        await retryWithCorrection(threadId, correctedResponse);
    } else {
        // Enviar respuesta final
        await sendWhatsAppMessage(chatId, correctedResponse);
    }
}
```

## 5. An√°lisis de Im√°genes con `analyzeImage`

Una funcionalidad robusta que utiliza `gpt-4o-mini` para analizar im√°genes en contexto hotelero:

```typescript
async function analyzeImage(imageUrl: string, userJid: string): Promise<string> {
    try {
        // Si no hay URL, obtener del endpoint de Whapi
        if (!imageUrl) {
            const mediaResponse = await fetch(`${WHAPI_BASE_URL}/messages/${messageId}`, {
                headers: { 'Authorization': `Bearer ${WHAPI_TOKEN}` }
            });
            imageUrl = mediaResponse.data.media_url;
        }
        
        const response = await openai.chat.completions.create({
            model: 'gpt-4o-mini',
            messages: [{
                role: 'user',
                content: [
                    { 
                        type: 'text', 
                        text: 'Analiza esta imagen en contexto hotelero. Describe qu√© ves de manera concisa y √∫til para un asistente de hotel. M√°ximo 100 palabras.' 
                    },
                    { 
                        type: 'image_url', 
                        image_url: { url: imageUrl, detail: 'low' } 
                    }
                ]
            }],
            max_tokens: 150,
            temperature: 0.3
        });
        
        const analysis = response.choices[0].message.content;
        terminalLog.success(`üì∑ Image analyzed: "${analysis.substring(0, 50)}..."`);
        
        return analysis;
    } catch (error) {
        terminalLog.imageError(getShortUserId(userJid), `Image analysis failed: ${error.message}`);
        return '[Error al analizar imagen]';
    }
}
```

**Uso en el flujo**:
1. La URL se guarda en `pendingImages` para contenido multimodal
2. Se obtiene una descripci√≥n textual que se agrega al buffer con "üì∑"
3. Ambos (descripci√≥n + URL original) se env√≠an a OpenAI para contexto completo

## 6. Env√≠o y Validaci√≥n de Respuestas

### `validateAndCorrectResponse` - Control de Calidad
Compara la respuesta de la IA con los datos crudos de las `tool outputs` usando la distancia de Levenshtein:

```typescript
async function validateAndCorrectResponse(response: string, originalOutputs?: string): Promise<{ correctedResponse: string, needsRetry: boolean }> {
    if (!originalOutputs) return { correctedResponse: response, needsRetry: false };
    
    // Calcular distancia de Levenshtein
    const distance = levenshtein(response, originalOutputs);
    const similarity = 1 - (distance / Math.max(response.length, originalOutputs.length));
    
    // Si la similitud es muy baja, posible alucinaci√≥n
    const needsRetry = similarity < 0.3 && userRetryState.get(userJid)?.canRetry();
    
    return {
        correctedResponse: response,
        needsRetry
    };
}
```

**Control de Reintentos**:
- M√°ximo 1 reintento cada 5 minutos por usuario (`userRetryState`)
- Si se detecta error, se formula un `correctiveMessage` interno
- Se ejecuta un nuevo run con el mensaje correctivo

### `sendWhatsAppMessage` - Entrega Final
```typescript
async function sendWhatsAppMessage(chatId: string, message: string): Promise<boolean> {
    const userState = getOrCreateUserState(extractUserFromChat(chatId));
    
    // Determinar si usar voz
    const shouldUseVoice = ENABLE_VOICE_RESPONSES && 
                          userState.lastInputVoice && 
                          !isQuoteOrPriceMessage(message);
    
    if (shouldUseVoice) {
        try {
            // TTS con voz nova
            const audioResponse = await openai.audio.speech.create({
                model: 'tts-1',
                voice: 'nova',
                input: message.substring(0, 4000) // L√≠mite de caracteres
            });
            
            const audioBuffer = Buffer.from(await audioResponse.arrayBuffer());
            const audioBase64 = audioBuffer.toString('base64');
            
            await whapiClient.sendVoiceMessage(chatId, audioBase64);
            userState.lastInputVoice = false; // Reset flag
            
            terminalLog.response(getShortUserId(userState.userJid), `üîä Voice: "${message.substring(0, 50)}..."`);
            return true;
        } catch (error) {
            terminalLog.warning(`Voice TTS failed, falling back to text: ${error.message}`);
            // Continuar con env√≠o de texto
        }
    }
    
    // Env√≠o de texto con divisi√≥n inteligente
    const chunks = splitMessageIntelligently(message);
    
    for (let i = 0; i < chunks.length; i++) {
        const chunk = chunks[i];
        const typingTime = i === 0 ? 3000 : 2000; // Primer chunk m√°s tiempo
        
        await whapiClient.sendTextMessage(chatId, chunk, { typing_time: typingTime });
        
        // Registrar para evitar self-loops
        const messageId = `msg_${Date.now()}_${i}`;
        botSentMessages.set(messageId, true);
        setTimeout(() => botSentMessages.delete(messageId), 10 * 60 * 1000); // TTL 10min
    }
    
    terminalLog.response(getShortUserId(userState.userJid), message);
    return true;
}
```

**Divisi√≥n Inteligente de Mensajes**:
```typescript
function splitMessageIntelligently(message: string): string[] {
    // Dividir por p√°rrafos dobles
    let chunks = message.split('\n\n').filter(chunk => chunk.trim());
    
    // Si hay listas, dividir tambi√©n por elementos de lista
    chunks = chunks.flatMap(chunk => {
        if (chunk.includes(':') && /[‚Ä¢\-\*]/.test(chunk)) {
            return chunk.split(/(?=\n[‚Ä¢\-\*])/);
        }
        return [chunk];
    });
    
    return chunks.map(chunk => chunk.trim()).filter(chunk => chunk.length > 0);
}
```

## 7. Terminal Log - Feedback Visual para Desarrolladores

El `terminalLog` es el mecanismo principal de feedback visual en la consola, mostrando de forma limpia y formateada el flujo de la conversaci√≥n:

### Tipos de Logs Principales
```typescript
// Mensajes de usuario
terminalLog.message(userId, "üìù Hola, ¬øhay disponibilidad para ma√±ana?");

// Estados de presencia
terminalLog.typing(userId, "‚úçÔ∏è Usuario escribiendo...");
terminalLog.recording(userId, "üéôÔ∏è Usuario grabando...");

// Function calling
terminalLog.functionStart("‚öôÔ∏è check_availability({checkin: '2025-01-15', checkout: '2025-01-16'})");
terminalLog.functionSuccess("‚úÖ check_availability completed - 3 rooms available");
terminalLog.functionError("‚ùå check_availability failed: API timeout");

// Respuestas del asistente
terminalLog.response(userId, "üè† Excelente, tenemos 3 habitaciones disponibles para esas fechas...", 1250);

// Errores y warnings
terminalLog.error("‚ùå OpenAI API error: Rate limit exceeded");
terminalLog.warning("‚ö†Ô∏è Voice TTS failed, falling back to text");

// √âxitos del sistema
terminalLog.success("‚úÖ MANUAL_SYNC_SUCCESS - Agent message synchronized");
```

### Rate Limiting de Logs
Para evitar spam en la consola:
- **Typing/Recording logs**: M√°ximo uno cada 5 segundos por usuario
- **Webhook inv√°lidos**: M√°ximo uno cada minuto usando `webhookCounts` Map
- **Errores repetitivos**: Debouncing autom√°tico para errores similares

## 8. Impacto de Flujos de Inicio y Apagado

### Al Iniciar (`initializeBot`)
```typescript
async function initializeBot(): Promise<void> {
    // Recovery de runs hu√©rfanos (background task)
    setTimeout(async () => {
        await recoverOrphanedRuns();
    }, 5000);
    
    // Cleanup intervals
    setInterval(cleanupExpiredCaches, 10 * 60 * 1000); // 10min
    setInterval(logMemoryUsage, 5 * 60 * 1000); // 5min - alert >300MB
    setInterval(cleanupUserStates, 60 * 60 * 1000); // 1h - >24h inactive
    setInterval(cleanupGlobalBuffers, 10 * 60 * 1000); // 10min - >15min inactive
}

async function recoverOrphanedRuns(): Promise<void> {
    const threads = threadPersistence.getAllThreadsInfo();
    let cancelledCount = 0;
    
    for (const [userJid, threadInfo] of threads) {
        const runs = await openaiClient.beta.threads.runs.list(threadInfo.threadId, { limit: 10 });
        
        for (const run of runs.data) {
            if (['queued', 'in_progress', 'requires_action'].includes(run.status)) {
                await openaiClient.beta.threads.runs.cancel(threadInfo.threadId, run.id);
                const ageMinutes = (Date.now() - run.created_at * 1000) / (60 * 1000);
                
                terminalLog.warning(`üßπ ORPHANED_RUN_CANCELLED: ${run.id} (${ageMinutes.toFixed(1)}min old)`);
                cancelledCount++;
            }
        }
    }
    
    if (cancelledCount > 0) {
        terminalLog.success(`‚úÖ Recovery complete: ${cancelledCount} orphaned runs cancelled`);
    }
}
```

### Al Apagar (`setupSignalHandlers`)
```typescript
function setupSignalHandlers(): void {
    const gracefulShutdown = (signal: string) => {
        terminalLog.info(`üì§ ${signal} received, initiating graceful shutdown...`);
        
        // Limpiar todos los timers de buffers
        let timersCleaned = 0;
        for (const [userId, buffer] of globalMessageBuffers.entries()) {
            if (buffer.timer) {
                clearTimeout(buffer.timer);
                timersCleaned++;
            }
        }
        
        terminalLog.info(`üßπ Cleared ${timersCleaned} pending buffer timers`);
        
        // Cerrar servidor con timeout
        server.close(() => {
            terminalLog.success('‚úÖ Server shutdown complete');
            process.exit(0);
        });
        
        // Forzar salida si no se cierra en 5s
        setTimeout(() => {
            terminalLog.error('‚ùå Forced shutdown due to timeout');
            process.exit(1);
        }, 5000);
    };
    
    process.on('SIGTERM', () => gracefulShutdown('SIGTERM'));
    process.on('SIGINT', () => gracefulShutdown('SIGINT'));
    
    // Manejo de errores no capturados
    process.on('uncaughtException', (error, origin) => {
        terminalLog.fatal(`üíÄ UNCAUGHT EXCEPTION [${origin}]: ${error.message}\nStack: ${error.stack}`);
        setTimeout(() => process.exit(1), 2000);
    });
    
    process.on('unhandledRejection', (reason, promise) => {
        terminalLog.fatal(`üíÄ UNHANDLED REJECTION at: ${promise}, reason: ${reason}`);
        setTimeout(() => process.exit(1), 2000);
    });
}
```

## 9. M√©tricas y Observabilidad

### Request Tracing Completo
```typescript
// Inicio del request
const traceId = startRequestTracing(userJid, chatId);

// Etapas del procesamiento
updateRequestStage(traceId, 'init');              // Buffer consolidado
updateRequestStage(traceId, 'processing');        // Entrando a processWithOpenAI
updateRequestStage(traceId, 'function_calling');  // Ejecutando tools
updateRequestStage(traceId, 'post_tools_completed'); // Tools completados
updateRequestStage(traceId, 'completed');         // Respuesta enviada

// M√©tricas espec√≠ficas de OpenAI
logOpenAIUsage(
    run.usage.total_tokens,
    run.usage.prompt_tokens, 
    run.usage.completion_tokens,
    run.usage.completion_tokens_details?.reasoning_tokens || 0,
    run.usage.total_tokens / (duration / 1000) // tokensPerSecond
);

logOpenAILatency(duration, duration > 30000); // isHighLatency >30s

logPerformanceMetrics(
    duration,
    run.usage.total_tokens,
    response.length,
    duration < 10000 && run.usage.total_tokens < 2000, // isEfficient
    process.memoryUsage()
);

// Finalizaci√≥n
endRequestTracing(traceId, {
    duration: Date.now() - startTime,
    success: true,
    tokensUsed: run.usage.total_tokens,
    functionsCalled: toolCalls.length
});
```

## 10. Riesgos y Mitigaciones

### Race Conditions
**Problema**: M√∫ltiples requests simult√°neos del mismo usuario pueden causar conflictos.
**Mitigaci√≥n**: 
- `simpleLockManager` garantiza procesamiento secuencial por usuario
- Backoff exponencial en `add message` (hasta 15 intentos)
- Backoff post-tool (hasta 10 intentos)

### Memory Leaks
**Problemas identificados**:
- `globalMessageBuffers` sin limpieza ‚Üí **Mitigado**: Cleanup cada 10min para >15min inactivos
- `userRetryState` sin TTL ‚Üí **Sugerencia**: Agregar cleanup cada 5min
- `botSentMessages` crecimiento ‚Üí **Mitigado**: TTL autom√°tico de 10min por mensaje

### Acumulaci√≥n de Archivos Temporales
**Problema**: `transcribeAudio` usa `fs.unlink().catch(() => {})` ignorando errores.
**Riesgo**: Acumulaci√≥n en `/tmp/` si el unlink falla.
**Mitigaci√≥n sugerida**:
```typescript
// Cleanup peri√≥dico de archivos temporales
setInterval(() => {
    const tmpDir = '/tmp';
    const oneHourAgo = Date.now() - 60 * 60 * 1000;
    
    fs.readdir(tmpDir, (err, files) => {
        if (err) return;
        
        files.filter(f => f.startsWith('audio_')).forEach(file => {
            const filePath = path.join(tmpDir, file);
            fs.stat(filePath, (err, stats) => {
                if (!err && stats.mtime.getTime() < oneHourAgo) {
                    fs.unlink(filePath).catch(() => {});
                }
            });
        });
    });
}, 60 * 60 * 1000); // Cleanup cada hora
```

### Billing Risk - Orphaned Runs
**Problema**: Runs activos hu√©rfanos facturan indefinidamente.
**Mitigaci√≥n**: `recoverOrphanedRuns` cancela **todos** los runs activos al iniciar.
**Trade-off**: Se pierden runs leg√≠timos en progreso, pero se evita facturaci√≥n excesiva.

### Dependencia de Red para Obtener URLs de Media
**Problema**: Si la URL de un audio o imagen no viene directamente en el payload del webhook, las funciones `transcribeAudio` y `analyzeImage` deben realizar una llamada `fetch` adicional a la API de Whapi (`/messages/{id}`) para obtener la URL del medio.
**Riesgo**: Fallo de red o timeout puede interrumpir el procesamiento de media, causando respuestas incompletas.
**Mitigaci√≥n actual**: Try/catch con fallback a mensajes de error (`[Error al analizar imagen]`, log `voiceError`).
**Sugerencia**: Implementar retry con backoff exponencial para llamadas a Whapi API.

## 11. Diagrama de Flujo de Datos Completo

```
üì® Webhook POST /hook
    ‚Üì [immediate 200 response]
üîÑ processWebhook(body)
    ‚Üì [discriminate event type]
    
üëÅÔ∏è PRESENCES                           üí¨ MESSAGES
    ‚Üì                                      ‚Üì
Update lastTyping                      [type discrimination]
setIntelligentTimer(10s)                   ‚Üì
terminalLog.typing (rate 5s)          TEXT ‚îÇ VOICE ‚îÇ IMAGE ‚îÇ MANUAL
subscribedPresences.add                    ‚îÇ       ‚îÇ       ‚îÇ
                                          ‚Üì       ‚Üì       ‚Üì       ‚Üì
                                    addToGlobal transcribe analyzeImage buffer
                                    Buffer + üìù  Audio +üé§  gpt-4o-mini separate
                                          ‚Üì       ‚Üì    üì∑+desc    chatId
                                    setIntelligent   pendingImages  timer 5s
                                    Timer(5s)    Timer(8-10s)  .push    ‚Üì
                                          ‚Üì       ‚Üì       ‚Üì    threads.
                                          ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ    messages
                                              ‚Üì           ‚îÇ    .create x2
                                        [timer expires]   ‚îÇ         ‚Üì
                                              ‚Üì           ‚îÇ    setThread
                                        processGlobal     ‚îÇ    metadata
                                        Buffer           ‚îÇ         ‚Üì
                                              ‚Üì           ‚îÇ    MANUAL_SYNC
                                        [check typing     ‚îÇ    _SUCCESS
                                         recent <10s]     ‚îÇ
                                              ‚Üì           ‚îÇ
                                        [if !active      ‚îÇ
                                         Processing]     ‚îÇ
                                              ‚Üì           ‚îÇ
                                        processCombined ‚Üê‚îò
                                        Message
                                              ‚Üì
                                        [isRunActive?]
                                              ‚Üì
                                        [retry 3x 1s if active]
                                              ‚Üì
                                        simpleLockManager
                                        .addToQueue
                                              ‚Üì
                                        üîí [sequential per user]
                                              ‚Üì
ü§ñ processWithOpenAI ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚Üì [startRequestTracing]
    ‚Üì [updateStage: init]
    ‚Üì
üìã getRelevantContext?
    ‚Üì [3h elapsed OR change name/labels OR first msg]
    ‚îú‚îÄ YES ‚Üí invalidateUserCaches + getPrecomputedContextBase(cache 1min)
    ‚îî‚îÄ NO ‚Üí direct message
    ‚Üì
üßµ get/create thread
    ‚Üì [threadPersistence]
üì° subscribeToPresence (if !subscribedPresences.has)
    ‚Üì
üßπ cleanupOldRuns (if new thread)
    ‚Üì
üìù create multimodal message
    ‚Üì [text + pendingImages, clear after]
‚ñ∂Ô∏è create run
    ‚Üì
üîÑ polling loop (while attempts < 30, setTimeout 1000)
    ‚Üì [with backoff on race: min((attempt+1)*1000, 5000) max 15]
    ‚Üì
STATUS CHECK:
‚îú‚îÄ completed ‚Üí get response ‚Üí validateAndCorrectResponse
‚îÇ                ‚Üì [levenshtein distance]
‚îÇ                ‚îú‚îÄ needsRetry + canRetry ‚Üí correctiveMessage + retry run
‚îÇ                ‚îî‚îÄ send final response
‚îÇ
‚îú‚îÄ requires_action ‚Üí üõ†Ô∏è FUNCTION CALLING
‚îÇ    ‚Üì [inline handling, no separate function]
‚îÇ    ‚îú‚îÄ import('./functions/registry/function-registry.js')
‚îÇ    ‚îú‚îÄ registerToolCall + updateToolCallStatus('executing')
‚îÇ    ‚îú‚îÄ terminalLog.functionStart('‚öôÔ∏è function_name(...)')
‚îÇ    ‚îú‚îÄ executeFunction(name, args)
‚îÇ    ‚îú‚îÄ updateToolCallStatus('success'/'error')
‚îÇ    ‚îú‚îÄ terminalLog.functionSuccess/Error
‚îÇ    ‚îú‚îÄ submitToolOutputs
‚îÇ    ‚îî‚îÄ polling post-tool: min((postAttempts+1)*500, 5000) max 10
‚îÇ                ‚Üì
‚îÇ            get final response
‚îÇ
‚îî‚îÄ failed/timeout ‚Üí log error
                    ‚Üì
üì§ sendWhatsAppMessage
    ‚Üì [shouldUseVoice check]
    ‚îú‚îÄ VOICE ‚Üí TTS nova mp3 base64 ‚Üí /messages/voice ‚Üí clear lastInputVoice
    ‚îÇ           ‚Üì [fallback on error]
    ‚îî‚îÄ TEXT ‚Üí split chunks (\n\n or lists) ‚Üí typing_time ‚Üí /messages/text
                ‚Üì
            botSentMessages.set(id, TTL 10min)
                ‚Üì
            terminalLog.response
                ‚Üì
üèÅ endRequestTracing(summary)

[BOOT IMPACT] recoverOrphanedRuns (5s delay) ‚Üí cancel ALL active runs ‚Üí log ORPHANED_CANCELLED
[SHUTDOWN IMPACT] clear all buffer timers ‚Üí server.close(5s timeout) ‚Üí exit(0/1)
```

## 12. Preparaci√≥n para Modularizaci√≥n

### Separaci√≥n Sugerida por M√≥dulos

#### `webhook.ts` - Manejo de Webhooks
- `processWebhook()`
- `handlePresenceEvents()`
- `handleMessageEvents()`
- Validaci√≥n y filtrado de webhooks

#### `bufferManager.ts` - Gesti√≥n de Agrupaci√≥n
- `addToGlobalBuffer()`
- `setIntelligentTimer()`
- `processGlobalBuffer()`
- Cleanup de buffers inactivos

#### `lockManager.ts` - Control de Concurrencia
- `simpleLockManager`
- `processCombinedMessage()`
- Queue management por usuario

#### `openaiOrchestrator.ts` - L√≥gica de OpenAI
- `processWithOpenAI()`
- Function calling inline
- Polling y retry logic
- Context injection

#### `mediaProcessor.ts` - Manejo de Media
- `transcribeAudio()`
- `analyzeImage()`
- Gesti√≥n de archivos temporales

#### `responseHandler.ts` - Env√≠o de Respuestas
- `sendWhatsAppMessage()`
- `validateAndCorrectResponse()`
- Voice TTS y text splitting

### Interfaces de Comunicaci√≥n
```typescript
// Eventos entre m√≥dulos
interface WebhookEvent {
    type: 'message' | 'presence';
    userId: string;
    chatId: string;
    data: any;
}

interface ProcessingRequest {
    userMessage: string;
    userId: string;
    chatId: string;
    context?: any;
    images?: string[];
}

interface OpenAIResponse {
    success: boolean;
    response?: string;
    error?: string;
    tokensUsed: number;
    duration: number;
}
```

Esta estructura modular facilitar√°:
- **Testing independiente** de cada componente
- **Escalabilidad horizontal** (diferentes instancias para diferentes m√≥dulos)
- **Mantenimiento focalizado** (cambios en OpenAI no afectan webhook handling)
- **Reusabilidad** (el bufferManager puede usarse para otros tipos de eventos)

---

La secci√≥n 6 representa el coraz√≥n del sistema, donde convergen todas las tecnolog√≠as y se orquesta la experiencia del usuario final. Su complejidad refleja la sofisticaci√≥n necesaria para manejar conversaciones naturales, multimodales y con function calling en un entorno de producci√≥n robusto.