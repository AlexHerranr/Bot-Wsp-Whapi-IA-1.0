# Implementaci√≥n de Voz a Voz üé§ ‚Üí üîä

## Estado Actual ‚úÖ

La funcionalidad de voz a voz est√° **completamente implementada** en el c√≥digo, pero tiene una limitaci√≥n con WHAPI en entornos de desarrollo local.

### Lo que funciona:

1. **Detecci√≥n de mensajes de voz** ‚úÖ
   - El bot detecta correctamente cuando recibe mensajes tipo `voice`, `audio` o `ptt`
   - Se marca el estado `lastInputVoice = true` para el usuario

2. **Transcripci√≥n (opcional)** ‚úÖ
   - Si est√° habilitada (`ENABLE_VOICE_TRANSCRIPTION=true`), transcribe el audio
   - El texto se prefija con "üé§ [NOTA DE VOZ]:" para identificaci√≥n

3. **Instrucciones especiales a OpenAI** ‚úÖ
   - Cuando detecta nota de voz, agrega instrucciones para respuestas breves
   - OpenAI responde de forma concisa (2-3 oraciones m√°ximo)

4. **Generaci√≥n de audio TTS** ‚úÖ
   - Convierte la respuesta a voz usando OpenAI TTS
   - Genera archivos OGG en `tmp/audio/`
   - Crea URLs p√∫blicas para los archivos

5. **Decisi√≥n inteligente** ‚úÖ
   - SIEMPRE responde con voz cuando el usuario envi√≥ voz
   - Ignora otros criterios (longitud, probabilidad aleatoria)

### Limitaci√≥n con WHAPI ‚ö†Ô∏è

WHAPI devuelve **error 500** al intentar descargar archivos desde URLs de ngrok. Esto es una limitaci√≥n conocida en desarrollo local.

## C√≥digo Implementado

### 1. Procesamiento de mensajes de voz en el webhook

```typescript
// En app-unified.ts, l√≠neas ~2960-2990
if (['voice', 'audio', 'ptt'].includes(message.type) && !message.from_me) {
    // Marcar que el usuario envi√≥ voz
    const userState = globalUserStates.get(userId) || { lastInputVoice: false };
    userState.lastInputVoice = true;
    globalUserStates.set(userId, userState);
    
    if (process.env.ENABLE_VOICE_TRANSCRIPTION === 'true') {
        // Transcribir audio
        const audioUrl = message.voice?.url || message.audio?.url || message.ptt?.url;
        const transcription = await transcribeAudio(audioUrl, userId, message.id);
        const audioText = `üé§ [NOTA DE VOZ]: ${transcription}`;
        
        // Agregar al buffer con flag de voz
        addToGlobalBuffer(userId, audioText, chatId, userName, true);
    }
}
```

### 2. Detecci√≥n de mensaje de voz en OpenAI

```typescript
// En processWithOpenAI, l√≠neas ~1820-1835
const isVoiceMessage = userMsg.includes('üé§ [NOTA DE VOZ]');
let messageWithContext = temporalContext + userMsg;

if (isVoiceMessage) {
    const voiceInstructions = `\n\n[INSTRUCCI√ìN DEL SISTEMA: El usuario envi√≥ una NOTA DE VOZ. Por favor responde de forma CONCISA y NATURAL, como si estuvieras hablando. Usa un tono conversacional, evita listas largas o informaci√≥n muy detallada. M√°ximo 2-3 oraciones cortas.]`;
    messageWithContext = temporalContext + userMsg + voiceInstructions;
}
```

### 3. Decisi√≥n de responder con voz

```typescript
// En sendWhatsAppMessage, l√≠neas ~655-660
const shouldUseVoice = process.env.ENABLE_VOICE_RESPONSES === 'true' && (
    userState?.lastInputVoice  // Si el usuario envi√≥ voz, SIEMPRE responder con voz
);
```

## Configuraci√≥n Requerida

```env
# En .env
ENABLE_VOICE_RESPONSES=true
ENABLE_VOICE_TRANSCRIPTION=true
TTS_VOICE=nova  # Opciones: alloy, echo, fable, onyx, nova, shimmer
WHISPER_LANGUAGE=es
MAX_AUDIO_SIZE=26214400  # 25MB
MAX_AUDIO_DURATION=300   # 5 minutos
```

## Soluciones para Producci√≥n

### Opci√≥n 1: Railway/Cloud Run (Recomendado)
En producci√≥n con una URL p√∫blica real, WHAPI deber√≠a poder descargar los archivos sin problemas.

### Opci√≥n 2: CDN o Almacenamiento Externo
```javascript
// Pseudoc√≥digo para subir a S3/Cloudinary
const audioBuffer = await ttsResponse.arrayBuffer();
const publicUrl = await uploadToS3(audioBuffer, fileName);
// Usar publicUrl en lugar de URL local
```

### Opci√≥n 3: Base64 con conversi√≥n
Investigar si WHAPI tiene un endpoint para subir archivos directamente y obtener una URL interna.

## Tests Disponibles

1. **Test completo**: `node tests/test-voice-to-voice.mjs`
   - Simula una nota de voz real con URL de audio

2. **Test simplificado**: `node tests/test-voice-simple.mjs`
   - Simula transcripci√≥n ya procesada

## Logs para Debugging

```bash
# Ver todos los logs de voz
tail -f logs/bot-session-*.log | grep -E "(VOICE|üé§|üîä)"

# Ver errores espec√≠ficos
grep -E "VOICE_.*ERROR" logs/bot-session-*.log

# Ver flujo completo
grep "573003913251" logs/bot-session-*.log | grep -E "(VOICE|MESSAGE_RECEIVED|OPENAI)"
```

## Resumen

‚úÖ **La implementaci√≥n est√° completa y funcional**
‚ö†Ô∏è **Limitaci√≥n**: WHAPI no puede acceder a URLs de ngrok en desarrollo local
üöÄ **Soluci√≥n**: Funcionar√° correctamente en producci√≥n con URLs p√∫blicas reales