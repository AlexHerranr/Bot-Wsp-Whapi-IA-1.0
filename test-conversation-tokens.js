const fetch = require('node-fetch');
require('dotenv').config({ path: '.env.test' });

async function testConversationTokens() {
    const apiKey = process.env.OPENAI_API_KEY;
    
    console.log('üß™ TEST DE TOKENS EN CONVERSACI√ìN CONTINUA\n');
    
    // Primero crear una conversaci√≥n
    console.log('1Ô∏è‚É£ Creando conversaci√≥n...');
    const convResponse = await fetch('https://api.openai.com/v1/conversations', {
        method: 'POST',
        headers: {
            'Authorization': `Bearer ${apiKey}`,
            'Content-Type': 'application/json',
        },
        body: JSON.stringify({})
    });
    
    const conversation = await convResponse.json();
    const conversationId = conversation.id;
    console.log('‚úÖ Conversation ID:', conversationId);
    
    // Array para guardar los resultados
    const messages = [];
    const tokenHistory = [];
    
    // Mensaje 1
    console.log('\nüì§ Mensaje 1: "Hola, necesito informaci√≥n"');
    const response1 = await fetch('https://api.openai.com/v1/responses', {
        method: 'POST',
        headers: {
            'Authorization': `Bearer ${apiKey}`,
            'Content-Type': 'application/json',
        },
        body: JSON.stringify({
            model: 'gpt-5-mini-2025-08-07',
            conversation: conversationId,
            instructions: 'Eres un asistente de hotel. S√© breve.',
            input: [
                {
                    type: 'message',
                    role: 'user',
                    content: [{ type: 'input_text', text: 'Hola, necesito informaci√≥n' }]
                }
            ],
            max_output_tokens: 50,
            store: true
        })
    });
    
    const data1 = await response1.json();
    messages.push({ user: 'Hola, necesito informaci√≥n', assistant: data1.output?.[0]?.content?.[0]?.text });
    tokenHistory.push({
        mensaje: 1,
        input: data1.usage?.input_tokens,
        output: data1.usage?.output_tokens,
        total: data1.usage?.total_tokens
    });
    
    console.log('üìä Tokens:', data1.usage);
    
    // Esperar un poco
    await new Promise(resolve => setTimeout(resolve, 1000));
    
    // Mensaje 2
    console.log('\nüì§ Mensaje 2: "¬øCu√°l es el precio de una habitaci√≥n?"');
    const response2 = await fetch('https://api.openai.com/v1/responses', {
        method: 'POST',
        headers: {
            'Authorization': `Bearer ${apiKey}`,
            'Content-Type': 'application/json',
        },
        body: JSON.stringify({
            model: 'gpt-5-mini-2025-08-07',
            conversation: conversationId,  // Misma conversaci√≥n
            input: [
                {
                    type: 'message',
                    role: 'user',
                    content: [{ type: 'input_text', text: '¬øCu√°l es el precio de una habitaci√≥n?' }]
                }
            ],
            max_output_tokens: 50,
            store: true
        })
    });
    
    const data2 = await response2.json();
    messages.push({ user: '¬øCu√°l es el precio de una habitaci√≥n?', assistant: data2.output?.[0]?.content?.[0]?.text });
    tokenHistory.push({
        mensaje: 2,
        input: data2.usage?.input_tokens,
        output: data2.usage?.output_tokens,
        total: data2.usage?.total_tokens
    });
    
    console.log('üìä Tokens:', data2.usage);
    
    // Esperar un poco
    await new Promise(resolve => setTimeout(resolve, 1000));
    
    // Mensaje 3
    console.log('\nüì§ Mensaje 3: "¬øY para dos personas?"');
    const response3 = await fetch('https://api.openai.com/v1/responses', {
        method: 'POST',
        headers: {
            'Authorization': `Bearer ${apiKey}`,
            'Content-Type': 'application/json',
        },
        body: JSON.stringify({
            model: 'gpt-5-mini-2025-08-07',
            conversation: conversationId,  // Misma conversaci√≥n
            input: [
                {
                    type: 'message',
                    role: 'user',
                    content: [{ type: 'input_text', text: '¬øY para dos personas?' }]
                }
            ],
            max_output_tokens: 50,
            store: true
        })
    });
    
    const data3 = await response3.json();
    messages.push({ user: '¬øY para dos personas?', assistant: data3.output?.[0]?.content?.[0]?.text });
    tokenHistory.push({
        mensaje: 3,
        input: data3.usage?.input_tokens,
        output: data3.usage?.output_tokens,
        total: data3.usage?.total_tokens
    });
    
    console.log('üìä Tokens:', data3.usage);
    
    // An√°lisis
    console.log('\n\nüìà AN√ÅLISIS DE TOKENS:');
    console.log('‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ');
    console.log('Msg | Input | Output | Total | ¬øAcumulado?');
    console.log('‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ');
    
    let totalAcumulado = 0;
    tokenHistory.forEach((t, i) => {
        totalAcumulado += t.total;
        const esAcumulado = t.total > totalAcumulado - t.total ? '‚ùå NO' : '‚úÖ S√ç';
        console.log(`${t.mensaje}   | ${String(t.input).padEnd(5)} | ${String(t.output).padEnd(6)} | ${String(t.total).padEnd(5)} | ${esAcumulado}`);
    });
    
    console.log('‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ');
    console.log(`Total manual acumulado: ${totalAcumulado}`);
    
    // Test con previous_response_id tambi√©n
    console.log('\n\nüîÑ TEST CON PREVIOUS_RESPONSE_ID:');
    
    let previousId = null;
    const tokenHistory2 = [];
    
    // Primera llamada
    const resp1 = await fetch('https://api.openai.com/v1/responses', {
        method: 'POST',
        headers: {
            'Authorization': `Bearer ${apiKey}`,
            'Content-Type': 'application/json',
        },
        body: JSON.stringify({
            model: 'gpt-5-mini-2025-08-07',
            instructions: 'Eres un asistente de hotel.',
            input: [
                {
                    type: 'message',
                    role: 'user',
                    content: [{ type: 'input_text', text: 'Hola' }]
                }
            ],
            max_output_tokens: 30,
            store: true
        })
    });
    
    const d1 = await resp1.json();
    previousId = d1.id;
    tokenHistory2.push({ msg: 1, tokens: d1.usage?.total_tokens });
    
    // Segunda llamada con previous_response_id
    const resp2 = await fetch('https://api.openai.com/v1/responses', {
        method: 'POST',
        headers: {
            'Authorization': `Bearer ${apiKey}`,
            'Content-Type': 'application/json',
        },
        body: JSON.stringify({
            model: 'gpt-5-mini-2025-08-07',
            previous_response_id: previousId,
            input: [
                {
                    type: 'message',
                    role: 'user',
                    content: [{ type: 'input_text', text: '¬øTienen piscina?' }]
                }
            ],
            max_output_tokens: 30,
            store: true
        })
    });
    
    const d2 = await resp2.json();
    tokenHistory2.push({ msg: 2, tokens: d2.usage?.total_tokens });
    
    console.log('\nCon previous_response_id:');
    console.log('Mensaje 1:', tokenHistory2[0].tokens, 'tokens');
    console.log('Mensaje 2:', tokenHistory2[1].tokens, 'tokens (¬øincluye contexto anterior?)');
    
    console.log('\n\nüéØ CONCLUSI√ìN:');
    if (tokenHistory[1].input > tokenHistory[0].input) {
        console.log('‚úÖ Los tokens SE ACUMULAN - OpenAI cuenta todo el contexto');
    } else {
        console.log('‚ùå Los tokens NO se acumulan - Solo cuenta el mensaje actual');
    }
}

testConversationTokens().catch(console.error);
