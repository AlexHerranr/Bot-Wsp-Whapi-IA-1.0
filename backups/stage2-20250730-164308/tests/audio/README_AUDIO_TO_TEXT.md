# üé§‚û°Ô∏èüìù Sistema Audio-to-Text (Transcripci√≥n)

## üìã Descripci√≥n General

El sistema de **Audio-to-Text** permite al bot transcribir notas de voz y archivos de audio que los usuarios env√≠an por WhatsApp, convirti√©ndolos en texto para que el Assistant pueda procesarlos y responder adecuadamente.

## üîß Componentes T√©cnicos

### 1. **Detecci√≥n de Audio**
```typescript
// En app-unified.ts l√≠nea ~3333
if (message.type === 'voice' || message.type === 'audio' || message.type === 'ptt') {
    // Marcar que el usuario envi√≥ voz
    userState.lastInputVoice = true;
    
    // Procesar transcripci√≥n
    const transcription = await transcribeAudio(audioUrl, userId, userName, message.id);
}
```

### 2. **Funci√≥n de Transcripci√≥n**
```typescript
// Funci√≥n transcribeAudio (l√≠nea ~333)
async function transcribeAudio(audioUrl: string, userId: string, userName?: string, messageId?: string): Promise<string> {
    // 1. Descargar archivo de audio desde WHAPI
    const audioResponse = await fetch(finalAudioUrl);
    const audioBuffer = await audioResponse.arrayBuffer();
    
    // 2. Crear objeto File para Whisper
    const audioFile = new File([new Uint8Array(audioBuffer)], 'audio.ogg', { type: 'audio/ogg' });
    
    // 3. Transcribir con OpenAI Whisper
    const transcription = await openai.audio.transcriptions.create({
        file: audioFile,
        model: 'whisper-1',
        language: 'es',
        response_format: 'json'
    });
    
    return transcription.text;
}
```

## üéØ Flujo Completo

```mermaid
graph TD
    A[Usuario env√≠a nota de voz] --> B[WHAPI recibe audio]
    B --> C[Bot detecta type: 'voice'/'ptt'/'audio']
    C --> D[Marcar userState.lastInputVoice = true]
    D --> E[Obtener URL del archivo de audio]
    E --> F[Descargar archivo desde WHAPI]
    F --> G[Crear File object para Whisper]
    G --> H[Enviar a OpenAI Whisper API]
    H --> I[Recibir transcripci√≥n en texto]
    I --> J[Procesar con OpenAI Assistant]
    J --> K[Generar respuesta contextual]
```

## ‚öôÔ∏è Configuraci√≥n

### Variables de Entorno
```bash
# Habilitar transcripci√≥n de voz
ENABLE_VOICE_TRANSCRIPTION=true

# Idioma para Whisper (espa√±ol)
WHISPER_LANGUAGE=es

# L√≠mites de archivo
MAX_AUDIO_SIZE=26214400      # 25MB
MAX_AUDIO_DURATION=300       # 5 minutos
```

### Formatos Soportados
- **WhatsApp nativo**: `.ogg` (Opus codec)
- **Archivos de audio**: `.mp3`, `.m4a`, `.wav`, `.webm`, `.flac`
- **L√≠mites**: 25MB m√°ximo, 5 minutos duraci√≥n

## üîç Caracter√≠sticas Especiales

### 1. **Formato Contextual**
El texto transcrito se env√≠a al Assistant con contexto:
```typescript
const formattedMessage = `üé§ [NOTA DE VOZ]: ${transcribedText}`;
```

### 2. **Manejo de Errores**
```typescript
try {
    const transcription = await transcribeAudio(audioUrl, userId, userName, message.id);
    // Procesamiento exitoso
} catch (error) {
    // Fallback: informar error sin detener el bot
    logError('VOICE_TRANSCRIPTION_ERROR', 'Error transcribiendo audio', {
        userId: getShortUserId(userId),
        error: error.message
    });
    
    // Respuesta de error amigable
    await sendWhatsAppMessage(userId, "Lo siento, no pude procesar tu nota de voz. ¬øPodr√≠as escribir tu mensaje?");
}
```

### 3. **Optimizaciones**
- **Detecci√≥n autom√°tica de formato** desde URL y headers
- **Logs t√©cnicos** para debugging y monitoreo
- **Timeout configurable** para evitar cuelgues
- **Retry logic** para fallos temporales

## üìä Logs y Monitoreo

### Eventos Registrados
```typescript
// Inicio de transcripci√≥n
logInfo('VOICE_TRANSCRIPTION_START', 'Iniciando transcripci√≥n de audio', {
    userId: shortUserId,
    audioUrl: finalAudioUrl
});

// Transcripci√≥n exitosa
logSuccess('VOICE_TRANSCRIPTION_SUCCESS', 'Audio transcrito exitosamente', {
    userId: shortUserId,
    transcriptionLength: transcribedText.length,
    audioSize: audioBuffer.length
});

// Error en transcripci√≥n
logError('VOICE_TRANSCRIPTION_ERROR', 'Error transcribiendo audio', {
    userId: shortUserId,
    error: error.message
});
```

## üß™ Testing

### Tests Disponibles
1. **`test-real-audio-flow.js`**: Flujo completo de transcripci√≥n
2. **`test-voice-response-ready.js`**: Verificaci√≥n de configuraci√≥n
3. **`test-audio-formats.js`**: Prueba de m√∫ltiples formatos

### Ejecutar Tests
```bash
# Test completo de transcripci√≥n
node tests/audio/test-real-audio-flow.js

# Verificar configuraci√≥n
node tests/audio/test-voice-response-ready.js
```

## üö® Troubleshooting

### Problemas Comunes

#### 1. "Invalid file format"
```bash
# Causa: Formato de audio no soportado
# Soluci√≥n: Verificar que sea .ogg, .mp3, .m4a, .wav, .webm, o .flac
```

#### 2. "File too large"
```bash
# Causa: Archivo mayor a 25MB
# Soluci√≥n: Ajustar MAX_AUDIO_SIZE o comprimir audio
```

#### 3. "Transcription timeout"
```bash
# Causa: Audio muy largo o conexi√≥n lenta
# Soluci√≥n: Aumentar OPENAI_TIMEOUT o verificar conexi√≥n
```

### Debug Mode
```bash
# Habilitar logs detallados
DEBUG_MODE=true
LOG_LEVEL=development
ENABLE_DETAILED_LOGS=true
```

## üìà M√©tricas de Rendimiento

### Tiempos Esperados
- **Audio 30s**: ~2-4 segundos transcripci√≥n
- **Audio 2min**: ~5-8 segundos transcripci√≥n  
- **Audio 5min**: ~10-15 segundos transcripci√≥n

### Recursos
- **CPU**: M√≠nimo durante transcripci√≥n (procesamiento en OpenAI)
- **Memoria**: ~10-20MB por archivo temporal
- **Red**: Dependiente del tama√±o del archivo

## üîÑ Integraci√≥n con Respuestas de Voz

Cuando un usuario env√≠a voz, el sistema:
1. **Transcribe el audio** (este m√≥dulo)
2. **Marca `lastInputVoice = true`**
3. **Procesa con Assistant**
4. **Responde con audio** (m√≥dulo Text-to-Audio)

Esta integraci√≥n completa el ciclo **voz ‚Üí voz** para una experiencia natural.

---

**üìù Nota**: Este sistema utiliza la API de Whisper de OpenAI, que es altamente precisa para espa√±ol y maneja autom√°ticamente ruido de fondo, diferentes acentos y velocidades de habla.