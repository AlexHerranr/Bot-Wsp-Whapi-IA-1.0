/**
 * ğŸ§ª TEST REAL - Flujo Completo de Audio
 * 
 * Simula el flujo completo de nota de voz:
 * 1. Archivo .ogg â†’ Whisper transcription
 * 2. TranscripciÃ³n â†’ OpenAI Assistant 
 * 3. Assistant â†’ Respuesta como asesor hotelero
 */

const fs = require('fs');
const path = require('path');
require('dotenv').config();

let OpenAI;
try {
    OpenAI = require('openai');
} catch (error) {
    console.error('âŒ OpenAI SDK no encontrado');
    process.exit(1);
}

const openai = new OpenAI({
    apiKey: process.env.OPENAI_API_KEY,
    timeout: 60000
});

const CONFIG = {
    audioFile: './WhatsApp Ptt 2025-07-24 at 11.25.38 AM.ogg',
    assistantId: process.env.ASSISTANT_ID,
    testUser: 'Cliente Test Audio',
    whisperModel: 'whisper-1' // Modelo de transcripciÃ³n
};

console.log('ğŸ§ª TEST REAL - FLUJO COMPLETO DE AUDIO\n');
console.log('ğŸ“‹ ConfiguraciÃ³n:');
console.log(`   - Archivo audio: ${CONFIG.audioFile}`);
console.log(`   - Assistant ID: ${CONFIG.assistantId}`);
console.log(`   - Usuario: ${CONFIG.testUser}`);
console.log(`   - Modelo Whisper: ${CONFIG.whisperModel}`);
console.log('â”€'.repeat(60));

async function testCompleteAudioFlow() {
    let threadId = null;
    
    try {
        // ğŸŸ¢ PASO 1: Verificar archivo de audio
        console.log('\nğŸ”„ PASO 1: Verificando archivo de audio...');
        
        const audioPath = path.resolve(CONFIG.audioFile);
        if (!fs.existsSync(audioPath)) {
            throw new Error(`Archivo no encontrado: ${audioPath}`);
        }
        
        const stats = fs.statSync(audioPath);
        console.log(`âœ… Audio encontrado: ${audioPath}`);
        console.log(`   - TamaÃ±o: ${(stats.size / 1024).toFixed(1)} KB`);
        console.log(`   - Formato: ${path.extname(audioPath).toLowerCase()}`);
        console.log(`   - Fecha: ${stats.mtime.toLocaleString()}`);
        
        // ğŸŸ¢ PASO 2: Transcribir audio con Whisper
        console.log('\nğŸ”„ PASO 2: Transcribiendo audio con Whisper...');
        
        const audioFile = fs.createReadStream(audioPath);
        const transcription = await openai.audio.transcriptions.create({
            file: audioFile,
            model: CONFIG.whisperModel,
            language: 'es', // EspaÃ±ol como en el bot real
            response_format: 'json'
        });
        
        const transcribedText = transcription.text;
        console.log(`âœ… TranscripciÃ³n completada:`);
        console.log(`   - Texto: "${transcribedText}"`);
        console.log(`   - Longitud: ${transcribedText.length} caracteres`);
        
        // ğŸŸ¢ PASO 3: Crear mensaje como en el bot real
        console.log('\nğŸ”„ PASO 3: Preparando mensaje para Assistant...');
        
        // Formato exacto del bot: "ğŸ¤ [NOTA DE VOZ]: [transcripciÃ³n]"
        const formattedMessage = `ğŸ¤ [NOTA DE VOZ]: ${transcribedText}`;
        console.log(`ğŸ“ Mensaje formateado: ${formattedMessage}`);
        
        // ğŸŸ¢ PASO 4: Crear thread y enviar al Assistant
        console.log('\nğŸ”„ PASO 4: Creando thread y enviando al Assistant...');
        
        const thread = await openai.beta.threads.create({
            metadata: {
                test: 'audio_transcription_test',
                user: CONFIG.testUser,
                timestamp: new Date().toISOString()
            }
        });
        
        threadId = thread.id;
        console.log(`âœ… Thread creado: ${threadId}`);
        
        // Crear mensaje en el thread
        const message = await openai.beta.threads.messages.create(threadId, {
            role: 'user',
            content: formattedMessage
        });
        
        console.log(`âœ… Mensaje enviado: ${message.id}`);
        
        // ğŸŸ¢ PASO 5: Ejecutar Assistant
        console.log('\nğŸ”„ PASO 5: Ejecutando Assistant...');
        
        const run = await openai.beta.threads.runs.create(threadId, {
            assistant_id: CONFIG.assistantId
        });
        
        console.log(`âœ… Run iniciado: ${run.id}`);
        
        // ğŸŸ¢ PASO 6: Esperar respuesta
        console.log('\nğŸ”„ PASO 6: Esperando respuesta del Assistant...');
        
        let runStatus = run;
        let attempts = 0;
        const maxAttempts = 30;
        
        while (['queued', 'in_progress', 'requires_action'].includes(runStatus.status) && attempts < maxAttempts) {
            await new Promise(resolve => setTimeout(resolve, 1000));
            runStatus = await openai.beta.threads.runs.retrieve(threadId, run.id);
            attempts++;
            
            process.stdout.write(`â³ Estado: ${runStatus.status} (${attempts}s)\r`);
        }
        
        console.log(`\nâœ… Run completado: ${runStatus.status}`);
        
        if (runStatus.status === 'completed') {
            // ğŸŸ¢ PASO 7: Obtener respuesta
            console.log('\nğŸ”„ PASO 7: Obteniendo respuesta...');
            
            const messages = await openai.beta.threads.messages.list(threadId, {
                limit: 10
            });
            
            const assistantResponse = messages.data.find(msg => 
                msg.role === 'assistant' && 
                msg.run_id === run.id
            );
            
            if (assistantResponse) {
                const responseText = assistantResponse.content[0]?.text?.value || 'Sin respuesta';
                
                console.log('ğŸ¤– RESPUESTA DEL ASSISTANT A LA NOTA DE VOZ:');
                console.log('â”€'.repeat(70));
                console.log(responseText);
                console.log('â”€'.repeat(70));
                
                // ğŸŸ¢ PASO 8: EstadÃ­sticas completas
                console.log(`\\nğŸ“Š EstadÃ­sticas del flujo completo:`);
                console.log(`   - Audio original: ${(stats.size / 1024).toFixed(1)} KB`);
                console.log(`   - TranscripciÃ³n: "${transcribedText.substring(0, 50)}..."`);
                console.log(`   - Longitud transcripciÃ³n: ${transcribedText.length} caracteres`);
                console.log(`   - Longitud respuesta: ${responseText.length} caracteres`);
                console.log(`   - Tiempo total: ~${attempts} segundos`);
                console.log(`   - Tokens usados: ${runStatus.usage?.total_tokens || 'N/A'}`);
                
                return {
                    success: true,
                    transcription: transcribedText,
                    response: responseText,
                    threadId: threadId,
                    runId: run.id,
                    duration: attempts,
                    audioSize: stats.size
                };
                
            } else {
                throw new Error('No se encontrÃ³ respuesta del Assistant');
            }
            
        } else if (runStatus.status === 'failed') {
            console.log(`\\nâŒ Run fallÃ³: ${runStatus.last_error?.message || 'Error desconocido'}`);
            return { success: false, error: runStatus.last_error?.message };
            
        } else {
            console.log(`\\nâš ï¸ Run terminÃ³ con estado inesperado: ${runStatus.status}`);
            return { success: false, error: `Estado inesperado: ${runStatus.status}` };
        }
        
    } catch (error) {
        console.error(`\\nâŒ Error durante el test: ${error.message}`);
        return { success: false, error: error.message };
        
    } finally {
        if (threadId) {
            console.log(`\\nğŸ§¹ Thread creado: ${threadId}`);
            console.log('   (Se mantiene para inspecciÃ³n manual si es necesario)');
        }
    }
}

// Ejecutar test
(async () => {
    const startTime = Date.now();
    
    try {
        const result = await testCompleteAudioFlow();
        const duration = ((Date.now() - startTime) / 1000).toFixed(1);
        
        console.log('\\n' + 'â•'.repeat(70));
        console.log('ğŸ“Š RESUMEN DEL TEST DE AUDIO COMPLETO');
        console.log('â•'.repeat(70));
        console.log(`âœ… Ã‰xito: ${result.success ? 'SÃ' : 'NO'}`);
        console.log(`â±ï¸ DuraciÃ³n total: ${duration}s`);
        
        if (result.success) {
            console.log(`ğŸ¤ TranscripciÃ³n: "${result.transcription}"`);
            console.log(`ğŸ§µ Thread ID: ${result.threadId}`);
            console.log(`ğŸƒ Run ID: ${result.runId}`);
            console.log(`ğŸ“ Audio: ${(result.audioSize / 1024).toFixed(1)} KB`);
            console.log(`ğŸ“ Respuesta: ${result.response.length} caracteres`);
            
            console.log('\\nğŸ¯ RESULTADO: âœ… FLUJO DE AUDIO EXITOSO');
            console.log('   - Whisper transcribiÃ³ correctamente el audio');
            console.log('   - Assistant procesÃ³ la nota de voz');
            console.log('   - Respuesta contextual como asesor hotelero');
            
        } else {
            console.log(`âŒ Error: ${result.error}`);
            console.log('\\nğŸ¯ RESULTADO: âŒ TEST FALLIDO');
        }
        
    } catch (error) {
        console.error(`\\nğŸ’¥ Error fatal: ${error.message}`);
    }
    
    console.log('\\nğŸ Test de audio completo finalizado\\n');
})();